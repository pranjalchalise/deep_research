{
  "metadata": {
    "key": "page:https://www.nature.com/articles/s40494-025-02280-y",
    "created": 1769981404.3770938,
    "ttl": 604800
  },
  "data": "AIGC based digital heritage reconstruction of Qing interior canopies Download PDF Download PDF Abstract This study explores the application of Artificial Intelligence Generated Content (AIGC) to the digital reconstruction of Qing-period interior canopy components, a representative form of traditional Chinese timberwork. To address fragmented archives and modeling inefficiency, we propose an integrated workflow combining historical image digitization, semantic lexicon building, prompt design, and image-to-model validation. A 76-term canopy glossary was embedded into a four-layer prompting template, and 312 images were generated across multiple platforms to analyze semantic response patterns and structural deviations. Validation using SketchUp confirmed stylistic fidelity with geometric deviations of only 3–4% and approximately 85% node interpretability. While AIGC excels in stylistic coherence and decorative richness, its limitations in structural logic require expert semantic annotation. Beyond reconstruction, the approach demonstrates potential for developing component ontologies, enriching BIM libraries, and supporting digital heritage conservation through rapid prototyping and stylistic diversity. Similar content being viewed by others Multi-agent collaborative pathways for Chinese traditional architectural image generation Article Open access 03 October 2025 Deep learning based approaches from semantic point clouds to semantic BIM models for heritage digital twin Article Open access 21 February 2024 Intelligent Hbim modeling of traditional timber architectural heritage, integrating machine vision and architectural expertise Article Open access 17 November 2025 Introduction The digital preservation of architectural heritage has become an increasingly significant concern in both academic research and practical conservation 1 , 2 . Within this context, the precise restoration of traditional building components has emerged as a critical challenge. Conventional approaches—such as manual drafting 3 , laser scanning 4 , or BIM-based parametric modeling 5 —can reconstruct structural logic to some extent 6 , 7 , 8 , but they often suffer from inefficiencies, incomplete archival records, and limited ability to reproduce ornamental detail 9 . These challenges are particularly pronounced in the case of xiaomuzuo (small-scale timberwork) components, whose intricate dimensions and complex joints pose substantial difficulties for accurate modeling. Recent advances in Artificial Intelligence Generated Content (AIGC) have opened new avenues for addressing these challenges 10 . Image generation models such as Midjourney, Stable Diffusion, and DALL·E leverage large-scale pre-trained datasets and semantic prompts to produce visually coherent outputs with stylistic consistency and ornamental richness 11 , 12 . Unlike traditional reconstruction methods that depend heavily on manual interpretation of drawings or fragmented measurements 13 , AIGC allows the rapid generation of multiple stylistic variants informed by historical semantics, decorative patterns, and spatial contexts. This provides valuable supplementary resources for cases where textual documentation is fragmentary and physical evidence is scarce 14 , 15 . Nevertheless, while AIGC demonstrates strong capabilities in stylistic representation and ornamental diversity 16 , its outputs often lack structural precision, dimensional accuracy, and explicit node articulation, limiting their direct applicability to digital modeling 17 , 18 . Bridging the gap between visual expressiveness and constructive logic thus emerges as a central problem in applying AIGC to heritage restoration. This study addresses the issue by focusing on the neiyan zhao (interior canopy) of the mid-Qing period, a representative example of small timberwork components. Drawing upon historical images and textual archives, it develops a methodological framework that integrates semantic extraction, prompt design, image generation, and model verification. Through comparative experiments across multiple platforms and consistency analysis within a SketchUp environment, this research evaluates both the potential and the limitations of AIGC in the digital reconstruction of architectural components. In doing so, it not only confirms AIGC’s strengths in stylistic and decorative representation but also identifies its deficiencies in structural logic and dimensional stability, while further exploring its implications for the construction of component ontologies and the expansion of BIM component libraries. Methods Historical image processing and semantic annotation The primary sources of visual information on mid-Qing interior canopies ( neiyan zhao ) are preserved in historical archives such as the Yangshi Lei Architectural Drawings, Qing Architectural Standards ( Qing Shi Yingzao Zeli ), and other repair records and architectural manuals. These materials, while invaluable, are generally characterized by non-standardized formats, including hand-drawn line sketches, schematic projections, and minimal dimensional annotations. Such features limit their direct usability for computational reconstruction. To transform these non-structured drawings into structured semantic data, a multi-step digital processing workflow was adopted. First, historical drawings were digitized and geometrically corrected, including the removal of perspective distortions, axis realignment, and local stroke compensation. The cleaned line drawings were then vectorized to isolate structural outlines from decorative noise, thereby recovering the essential geometric framework of canopy components. Subsequently, the drawings were segmented into logical construction zones based on traditional timberwork principles. For example, canopy images were divided into discrete structural sections—such as canopy surface, hanging panels, supporting brackets, side wings, and floral ornaments—each abstracted into elemental units (e.g., vertical, horizontal, projecting, and connecting elements). This step facilitated the binding of image features to semantic attributes. Finally, a three-layer annotation schema of component category—part name—decorative feature was applied to more than 40 representative mid-Qing canopy drawings (Table 1 ). Each drawing was systematically annotated with semantic blocks and relational attributes, creating an explicit mapping between visual representation and architectural terminology. This process resulted in the generation of vectorized semantic diagrams, anchoring tables for component terms, and relational datasets for proportional estimation. Collectively, this procedure converted fragmented historical imagery into structured semantic inputs, establishing the foundation for subsequent prompt design and AIGC-driven image generation. Table 1 Semantic Annotation of Typical Mid-Qing Dynasty Canopy Illustrations (Partial) Full size table Terminological semantic structuring The terminological system of traditional Chinese timber components is characterized by strong historical specificity and craft-oriented conventions. Terms not only describe structural logic and functional attributes but also embody ritual hierarchy, decorative aesthetics 19 , and cultural semantics 20 . In the case of interior canopies, frequently encountered terms include baozhu (corner posts), hengpi (transverse lintels), kan (sills), gexin (dividing panels), huayazi (ornamental brackets), xiaohuazhao (minor canopy panels), and xumizuo (Sumeru-style base). These terms appear recurrently in archival sources such as the Yangshi Lei Architectural Drawings and the Qing Architectural Standards, often accompanied by schematic illustrations or textual annotations (Table 2 ). Table 2 Semantic Lexicon of Architectural Components (Partial) Full size table However, inconsistencies across sources—such as variations in naming, overlapping scopes of reference, and ambiguous boundaries at component junctions—pose significant challenges for direct translation into modern semantic prompts. To address this, a systematic process of terminological structuring was undertaken. First, redundant or synonymous terms (e.g., chuihua and chuihua zhu ; yazi and huayazi ) were consolidated into unified synonym groups based on comparative analysis of historical drawings and textual descriptions. Second, terms were classified into three functional categories: structural components (e.g., sills, posts, lintels), ornamental components (e.g., floral brackets, decorative panels), and connecting elements (e.g., wooden dowels, bamboo pegs). Each entry was annotated with typical spatial position and relational hierarchy. Third, to enhance cross-lingual applicability and compatibility with existing AIGC semantic libraries, a bilingual glossary was compiled, supplemented with pinyin transliterations where necessary. The final output consisted of a semantic lexicon of 76 terms, organized into a four-layer mapping structure of terminology—function—spatial position—combinatorial logic. This lexicon was cross-referenced with annotated historical drawings, producing a tabular linkage between terms and visual anchors. As a result, the terminological structuring not only resolved ambiguities inherent in historical descriptions but also provided machine-readable semantic units, serving as the core linguistic resource for subsequent prompt construction and controlled image generation. Prompt logic design and corpus construction In the process of AIGC-based image generation, the prompt functions as the core parameter bridging textual semantics with visual representation For the digital reconstruction of traditional timber components 21 , prompt construction must encapsulate both structural semantics and stylistic fidelity. To achieve this, a four-tiered template system was established, integrating component terminology with the compositional features of the Yangshi Lei Architectural Drawings (Table 3 ). Table 3 Hierarchical Nested Structure of the Prompt Template System Full size table The framework consists of: (1) component semantics, specifying canopy types and sub-elements (e.g., luodi huazhao, feizhao, kangzhao ); (2) historical and stylistic context, incorporating temporal and spatial references (e.g., “Qing Dynasty, mid-18th century”); (3) decorative and compositional attributes, defining motifs and layout features (e.g., lotus carving, isometric view); and (4) representational parameters, regulating output style and rendering fidelity (e.g., technical illustration, photo-realistic rendering). This hierarchical design ensures both semantic accuracy and stylistic consistency. To operationalize the template, a “fixed template + semantic variable” mechanism was applied, embedding terms from the 76-entry lexicon into modular slots to generate multiple standardized prompt combinations. For example: “Qing Dynasty interior canopy, luodi huazhao with lotus carving and symmetrical hanging panels, technical architectural illustration, isometric view, high resolution”. In total, 46 prompt groups were constructed, covering the three principal canopy categories and their stylistic variants. The corpus was systematically tagged by component type, decorative style, historical context, and view angle, providing both a controlled input set for AIGC experiments and a reusable framework for future digital heritage reconstruction.To ensure the practical applicability of the proposed semantic corpus, image generation experiments were conducted across multiple AIGC platforms. The subsequent modeling validation process, including contour extraction, parametric assembly, and structural consistency evaluation, is elaborated in Results. Results Comparison of AIGC platforms and experimental workflow The effectiveness of AIGC-based image generation in the reconstruction of architectural components is influenced by multiple factors, including model architecture, semantic recognition capability, stylistic stability, and image clarity 22 . Among the mainstream platforms, Midjourney, Stable Diffusion, and DALL·E 3 represent three distinct paradigms, each based on different algorithmic frameworks and user interaction modes, thereby supporting varying levels of semantic control and visual expressiveness (see Table 4 ). Table 4 Analytical Comparison of AIGC-Based Visualization Schemes for Mid-Qing Interior Canopies Full size table Building on this foundation, the present study designed experiments informed by textual records from historical documents. Since canopy components are primarily described through textual accounts and line drawings in classical sources, their semantics are often fragmentary and ambiguous, necessitating image-based reconstruction and comparative validation via AIGC platforms. Specifically, representative sentences extracted from sources such as Lingguang Fu and Yangzhou Huafang Lu were used as the basis for prompt construction. These prompts were then input into the three platforms sequentially, allowing for the observation of differences in semantic interpretation, structural reconstruction, and stylistic control. This “textual semantics–platform generation–image output” workflow not only evaluates the feasibility of visualizing historical descriptions within an AIGC environment but also reveals the strengths and limitations of different platforms in the digital reconstruction of traditional canopy components (see Table 5 ). Table 5 Results of AIGC-Based Visualization Schemes for Mid-Qing Interior Canopies Full size table Through comparative evaluation, Midjourney v6.0 (accessed between January and March 2025) was ultimately selected as the primary platform for this study. All image generation experiments were conducted using the default model settings available during this period to ensure reproducibility. Its advantages in detail fidelity, line-art rendering, material simulation, and compositional control make it more suitable for generating canopy imagery than the alternatives. The experimental workflow was structured as follows: (a) Corpus Import and Prompt Assembly: Representative canopy-related semantic combinations were selected from the prompt template system developed in Section 2. Multiple trial prompts were tested to ensure coverage of semantic content, stylistic constraints, and image parameters. (b) Platform Access and Iterative Generation: Prompts were imported via the Midjourney web interface using the “/imagine” command, configured with v6 model settings (high resolution, style-stability mode) 23 . Each prompt generated four images, which were then compared and screened for precision. (c) Image Screening and Archival Labeling: Outputs with stylistic deviations, structural errors, or compositional ambiguities were discarded. Valid samples were archived and annotated with metadata covering component type, stylistic semantics, viewing angle, and compositional method. (d) Modeling Usability Assessment: The screened images were evaluated in relation to their clarity of outlines, logical coherence of component structures, and expression of proportional relationships, thereby establishing a sample base for subsequent 3D modeling validation. (Fig. 1 ). Fig. 1: Workflow for the AIGC-Based Digital Reconstruction of Interior Canopies. a Historical canopy drawings illustrating typological variations. b Semantic segmentation and structural layering of canopy elements. c Proportional analysis and component correspondence. d Reconstructed canopy models based on AIGC outputs and SketchUp validation. Full size image This workflow integrates systematic semantic control with usability evaluation of generated imagery, thus providing a standardized and scalable pathway for bridging image outputs and parametric modeling in the digital reconstruction of traditional architectural components. Image generation patterns and semantic response mechanisms Based on the constructed prompt corpus and experimental workflow, a total of 312 canopy images were generated, covering the principal categories of luodi zhao (floor-to-ceiling canopies), feizhao (projecting canopies), and kangzhao (kang-side canopies). Comparative analysis reveals that AIGC outputs not only exhibit diversified representational patterns but also manifest consistent semantic response mechanisms. Generation Patterns. The generated images can be broadly categorized into five dominant modes: (1) Isolated canopy renderings, focusing on the canopy body as a single unit with clear outlines and proportional coherence, suitable for direct modeling references; (2) Composite assemblies, highlighting the aggregation of multiple structural elements (e.g., rails, posts, brackets) to emphasize detail articulation and construction logic, useful for semantic annotation and component decomposition; (3) Contextual embeddings, situating the canopy within hall or eaves environments to accentuate materiality and lighting effects, offering scene-level interpretability; (4) Stylistic variations, depicting the same canopy type under different decorative or regional aesthetics, thereby reflecting the sensitivity of AIGC to stylistic modifiers; and (5) Aberrant outputs, characterized by structural distortions or compositional imbalance due to semantic misalignment, which, although unsuitable for modeling, provide valuable feedback for optimizing prompt design. Semantic Response Mechanisms. AIGC consistently demonstrates strong responsiveness to core component terms: prompts containing “ zhao ” reliably trigger canopy structures with recognizable decorative focal points, indicating the primacy of core semantics. By contrast, modifier terms exert direct influence on stylistic and ornamental details; for instance, “lotus carving” or “phoenix head bracket” prompts significantly altered decorative expression, while excessive stacking of modifiers often induced structural drift. Historical-contextual cues (e.g., “Qing style interior,” “ fu-shou pattern”) enhanced stylistic coherence and layering, underscoring the potential of contextual prompts for controlled style mapping. Finally, compositional prompts were highly sensitive to perspective and spatial adaptation: terms such as “isometric view” or “harmonized with surrounding environment” improved integration with architectural settings, aligning outputs more closely with modeling requirements (Fig. 2 ). Fig. 2: Semantic response variations driven by prompt design. a A front-elevation view of a Ming–Qing dynasty hall interior generated using a basic structural prompt, showing a “floor-to-ceiling floral screen” at the center. b Image generated with added stylistic modifiers such as “Fu-shou pattern,” “exquisite carvings,” and “Qing-style interior,” highlighting enhanced decorative richness and semantic sensitivity. c Output incorporating compositional cues including “isometric view” and “harmonized with the surrounding environment,” demonstrating improved spatial adaptation and contextual coherence. Full size image In summary, the generation process exhibits a regularized pattern summarized as “core terms stable — modifiers sensitive—context controllable—composition prone to drift.” These findings highlight the pivotal role of prompt design in shaping generative outcomes and provide empirical guidance for integrating AIGC imagery into component ontologies and modeling workflows. Semantic parsing of canopy images and extraction of key elements for 3D modeling AIGC-generated images provide visually intuitive and semantically explicit references for component modeling. However, to transform these visual outputs into structural data usable for digital reconstruction, it is necessary to conduct a deeper semantic analysis that uncovers the underlying logic of the depicted components 24 , 25 . Unlike traditional architectural drawings, AIGC images are predominantly stylized and often lack explicit dimensional annotations or technical specifications 9 . This necessitates the development of a robust semantic recognition framework and a set of extraction methods tailored for modeling purposes. In this study, a “partition–classification–mapping” approach was adopted for semantic parsing. First, each image was divided into structural zones according to the compositional logic of canopy design. Second, these zones were classified based on construction principles, identifying their functional attributes and mutual relationships. Finally, each visual segment was mapped to terms in the curated architectural lexicon, forming a semantic bridge of “image region—component terminology—structural meaning.” In canopy representations, three principal categories emerged: framing components, infill components, and auxiliary components. These correspond to established architectural terms such as baozhu (“vertical enclosing wooden column supporting the canopy, symmetrical, structural pillar in Qing Dynasty style”), hengpi (“horizontal lintel panel above openings, decorated fascia board with carved motifs, connecting columns”), and muxiaozi (“small wooden peg or pin for mortise–tenon joints, ensuring connectivity in traditional joinery”), as illustrated in Fig. 3 . Through this process, AIGC imagery was reorganized into a coherent construction language interpretable for architectural modeling 26 . Fig. 3: Structural semantic parsing of interior canopy images. Representative visualization of the semantic decomposition process and mapping of visual elements to architectural terminology. Full size image Once semantic recognition was achieved, extracted elements were translated into modeling parameters suitable for 3D operations 27 . The practice involved three key aspects: (1) Component Boundaries and Spatial Composition. AIGC images often depict canopy arch contours and symmetrical layouts with clarity. Primary outlines were traced in Photoshop and imported into SketchUp, where symmetry axes were established to define canopy width, eave height, and lateral expansion ratios with precision. By analyzing positional relationships, repetitive units and compositional logic were identified, facilitating array operations in subsequent modeling (Fig. 4 ). (2) Nodal Connections and Structural Logic. In floor-to-ceiling canopy images, mortise–tenon relationships and layered bracket transitions were frequently visible. Although AIGC images rarely captured joinery details explicitly, nodal configurations could be inferred from relative positioning, projection cues, and shadow overlaps. For instance, the inner frame of a circular canopy ( yuan guang zhao ) typically consists of three arcuated segments joined by semi-mortise pegs, with the central segment slightly elongated to bear transitional loads. In SketchUp, such inferred nodes were marked with auxiliary construction points to guide parametric assembly (Fig. 5 ). (3) Ornamental Features and Stylistic Information. A case study of AIGC outputs generated under the “ Jiangnan private garden style” prompt revealed canopy centers adorned with motifs such as pine patterns and scrollwork, rendered predominantly in vermilion. While these are non-structural elements, they serve as stylistic identifiers. In modeling, decorative regions were designated as texture-mapping slots and linked with material commands to ensure stylistic coherence while preserving geometric clarity (Fig. 6 ). Fig. 4: Spatial Relationships and Boundary Composition of Interior Canopy Structures. Primary outlines of AIGC-generated canopy images were traced and imported into SketchUp to identify symmetry axes, spatial boundaries, and compositional logic for subsequent modeling. Full size image Fig. 5: Connection nodes of circular canopy generated with sketch-based annotation support. The component depicted in the figure is a spring-retained dowel pin (拔紧销): a type of connection used in traditional timber construction, where the dowel pin is held in place by a spring mechanism, ensuring a tight and secure fit between structural components. Full size image Fig. 6: Expression of Stylistic Consistency in Alignment with Surrounding Ornamentation. AIGC-generated interior canopy under a “Jiangnan private garden style” prompt, showing non-structural decorative motifs such as pine patterns and scrollwork rendered in vermilion tones. These ornamental features are treated as texture-mapping regions in the modeling process to preserve stylistic coherence while maintaining geometric clarity. Full size image Overall, this semantic-to-parametric workflow confirms that AIGC-generated canopy imagery, when systematically parsed and structurally annotated, can be effectively converted into digital models. This bridges the gap between stylistic visualization and construction logic, laying the groundwork for scalable canopy component reconstruction. Component-level 3D modeling and image consistency validation Although AIGC-generated images exhibit notable strengths in morphological expression and stylistic restoration, their practical applicability for 3D modeling requires empirical validation 28 , 29 . Two representative timber canopy types— luodi zha o (floor-to-ceiling canopy) and fei zhao (projecting canopy)—were selected for modeling experiments in SketchUp, with AIGC imagery serving as the primary reference. The workflow integrated multiple plugins: Profile Builder for sectional extrusion and structural logic simulation, Curviloft for generating complex canopy curves, and Artisan for flexible detailing and fine-tuning. Rendering was performed using V-Ray for SketchUp to enhance stylistic coherence between the digital models and their AIGC counterparts 30 . The experimental process followed three stages:Outline Extraction. AIGC images were imported into SketchUp, where major structural boundaries (upper rails, middle rails, side frames) were traced using line-drawing tools;Sectional Construction. The traced outlines were extruded with Profile Builder to generate canopy frames and baozhu (supporting posts), with proportional analysis supplementing the absence of explicit dimensional data;Node and Ornament Assembly. Based on structural logic and decorative details observed in the images, nodes were modeled through grouped components and layered assemblies, while ornamental layers were organized via hierarchical grouping to simulate stylistic stratification. For validation, three image samples of each canopy type were modeled, resulting in six high-fidelity 3D models (Table 6 ).To systematically assess modeling quality, three categories of consistency indicators were employed: (1) Structural Contour Consistency. Comparative overlays measured geometric deviations in canopy width-to-height ratios and panel area distributions. Results showed that luodi zhao models exhibited average deviations within ±3.5%, while fei zhao models demonstrated slightly higher deviations (±4.2%) at transitional joints, maintaining overall structural coherence. (2) Nodal Logic Accuracy. Analysis of structural nodes (lintels, rails, xumizuo bases) revealed that approximately 85% of nodes in fei zhao models could be directly identified and reconstructed from the images. In luodi zhao , decorative occlusions necessitated supplemental inference based on construction knowledge, though logical consistency was preserved. (3) Stylistic Semantic Alignment. Using prompt-derived descriptors (e.g., “Qing-style canopy with lotus carving”), models were compared with images for stylistic expression, color configuration, and ornamental semantics. Results confirmed high visual and semantic consistency, although minor discrepancies remained in detailed decorations and proportional calibration. Table 6 Comparative Analysis between AIGC-Generated Schemes and 3D Models Full size table Beyond the overall deviation range of 3–4%, the error distribution revealed distinct spatial and semantic characteristics. Quantitatively, deviations were lowest in the primary structural frame—such as supporting posts and upper rails (average 2.8%)—while ornamental regions with dense carvings or curved profiles, including canopy crowns and hanging brackets, exhibited higher deviations (up to 4.5%). Semantically, the deviations correlated with the degree of structural determinacy: elements explicitly defined in historical drawings (e.g., baozhu and hengpi ) retained stable proportions, whereas components inferred from stylistic patterns (e.g., floral panels, scroll borders) showed greater geometric drift. This indicates that AIGC-generated imagery is more reliable for reconstructing macro-structural logic than for reproducing micro-ornamental geometries, underscoring the need for hierarchical weighting in subsequent modeling workflows”. Discussion This study has proposed and demonstrated a novel workflow for the digital reconstruction of traditional timber components in ancient Chinese architecture by leveraging AIGC technologies. It should be noted that the modeling validation was conducted on a limited sample of six canopy models (three of each type), which, while sufficient to demonstrate the feasibility of the proposed workflow, represents a preliminary proof of concept. Future studies should expand the sample size and diversity to include a broader range of architectural components and historical periods to further validate the scalability and generalizability of the approach. It is important to note that the validation process described in ‘Component-Level 3D Modeling and Image Consistency Validation’ focuses on testing the feasibility of the AIGC-to-model pipeline rather than directly validating the AIGC outputs against primary historical evidence, which may often be fragmented. This distinction underscores the methodological strength of the proposed framework in bridging fragmented data sources and generating coherent, usable digital assets. Unlike conventional approaches that primarily rely on manual modeling or HBIM supported by laser scanning, the proposed framework integrates historical image processing, semantic structuring, prompt logic design, and modeling validation into a coherent pipeline. The case study on mid-Qing interior canopies illustrates how fragmented textual records and schematic drawings can be transformed into semantically interpretable and visually expressive digital assets. This methodological contribution highlights the potential of AIGC not merely as a visualization tool but as a semantic-driven mechanism for bridging historical archives and digital reconstruction practices. Moreover, the spatial–semantic analysis of geometric deviations reveals how AIGC accuracy varies across different structural hierarchies. Primary load-bearing members display high dimensional stability, whereas decorative zones tend to accumulate greater distortions due to stylistic oversaturation in generative models. Recognizing such hierarchical bias not only clarifies the functional reliability of AIGC outputs but also informs the weighting of semantic parameters in future model training and evaluation. At the same time, the experiments reveal critical limitations inherent to current AIGC systems. While the generated images exhibited strong adaptability in stylistic expression, decorative richness, and visual coherence, they fell short in structural logic, dimensional precision, and node-level detail. Semantic drift was observed when modifiers were over-accumulated, leading to compositional inconsistencies. Moreover, the absence of explicit scale annotations and constructional accuracy necessitated supplementary human interpretation and cross-referencing with historical knowledge. Furthermore, while the current assessment of structural plausibility and stylistic fidelity was conducted by the research team, future work could incorporate evaluations by independent architectural historians or conservation experts to enhance the objectivity and credibility of the validation process. These findings suggest that AIGC-generated content, in its present stage, cannot directly replace precise architectural documentation or technical reconstruction but rather functions as a complementary resource that requires critical integration with established HBIM or parametric modeling workflows. Despite these constraints, the research points toward several promising avenues for future application. By systematically organizing architectural terminology into a semantic lexicon and embedding it within a structured prompt corpus, this study lays the groundwork for developing component ontologies and expanding BIM libraries. The demonstrated workflow also suggests pathways for rapid prototyping and stylistic diversity in the enrichment of architectural atlases. In a broader perspective, coupling AIGC with knowledge graphs, semantic annotation systems, and digital twin environments could substantially enhance the scalability and intelligence of heritage reconstruction. While the proposed methodology is primarily demonstrated in the context of Qing timber canopies, the ‘semantic lexicon -> prompt template’ approach could be adapted for other architectural styles where the design rules are well-documented but the visual examples are incomplete. For example, the same methodology could be applied to the reconstruction of Gothic tracery, Islamic muqarnas, or classical columns, where detailed documentation exists but visual records are lacking. This approach shows promise for expanding the applicability of AIGC in diverse architectural heritage contexts. Thus, while AIGC in its current form requires methodological supplementation, its potential to reshape the digital conservation and reinterpretation of traditional architecture is both evident and significant. Data availability The datasets generated and/or analyzed during the current study are available from the corresponding author on reasonable request. References Yi, X. et al. Study on consistency restoration of ancient architectural interior scenes based on AIGC technology. Furnit. Inter. Decor. 31 , 89–95 (2024). Google Scholar Cong, L. A framework study on the application of AIGC technology in the digital reconstruction of cultural heritage. applied mathematics and nonlinear. Sciences 9 , 1–21 (2024). Google Scholar Agnello, F. & Lo Brutto, M. Integrated surveying techniques in cultural heritage documentation: the “Quattro Canti” case. ISPRS International Archives of the Photogrammetry, Remote Sensing and Spatial. Inf. Sci. XXXVI-5/W1 , 17–22 (2006). Google Scholar Martinenko, A., Pejić, M., Obradović, M. & Debljović Ristić, N. Advancing 3D reconstruction: evaluating surveying techniques for medium-sized heritage objects. Measurement 256 , 118596 (2025). Article Google Scholar Clini, P., Mariotti, C., Angeloni, R. & Muñoz Cádiz, J. Architectural heritage digital representations for conservation strategies. ISPRS Arch. XLVIII-2/W4 , 111–202 (2024). Google Scholar Penjor, T., Banihashemi, S., Hajirasouli, A. & Golzad, H. Heritage building information modeling (HBIM) for heritage conservation: framework of challenges, gaps, and existing limitations of HBIM. Digit. Appl. Archaeol. Cult. Herit. 35 , e00366 (2024). Google Scholar Khan, M. S. et al. An integrated HBIM framework for the management of heritage buildings. Buildings 12 , 964 (2022). Article Google Scholar Klapa, P. et al. 3D heritage reconstruction through HBIM and multi-source data. Appl. Sci. 15 , 8929 (2025). Article CAS Google Scholar Lu, Y. et al. Design transformation pathways for AI-generated images in Chinese traditional architecture. Electronics 14 , 282 (2025). Article Google Scholar Ma, Y. et al. Exploring virtual restoration of architectural heritage through a systematic review. npj Heritage. Science 13 , 167 (2025). Google Scholar Chen, Y., Wu, Y., Sun, X., Ali, N. & Zhou, Q. Digital documentation and conservation of architectural heritage information: an application in modern Chinese architecture. Sustainability 15 , 7276 (2023). Article Google Scholar Zhang, Z., Zou, Y. & Xiao, W. Exploration of a virtual restoration practice route for architectural heritage based on evidence-based design: a case study of the Bagong House. Herit. Sci. 11 , 35 (2023). Article PubMed PubMed Central Google Scholar Chen, L., Dai, C., Zhou, M. & Lu, J. Development and application of an HBIM method for timber structures integrated with digital technologies. npj Heritage. Science 13 , 381 (2025). Google Scholar Croce, V., Caroti, G., Piemonte, A., De Luca, L. & Véron, P. H-BIM and artificial intelligence: classification of architectural heritage for semi-automatic scan-to-BIM reconstruction. Sensors 23 , 2497 (2023). Article PubMed PubMed Central Google Scholar Sun, S. et al. Application of generative artificial intelligence large models in the design domain. Furnit. Inter. Decor. 31 , 1–8 (2024). CAS Google Scholar Pan, S. et al. Constructing a sustainable evaluation framework for AIGC in cultural heritage design. Sustainability 17 , 910 (2025). Article Google Scholar Sapay, S. V., Abadi, K. P. W., Kusuma, G. C. W. & Islamiaty, N. J. F. Heritage building conservation: sustainable and digital modelling. Built Herit. 9 , 39 (2025). Article Google Scholar Chen, Y. et al. Opportunities and challenges of ChatGPT and Midjourney in home design applications. Furnit. Inter. Decor. 30 , 51–55 (2023). Google Scholar Chen, X. & Shi, Q. Reflections on the reconstruction of architectural heritage in China: a case study of Suzhou. J. Asian Architecture Build. Eng. 24 , 1–11 (2025). Google Scholar Li, L. et al. Semantic 3D modeling based on CityGML for ancient Chinese-style architectural roofs of digital heritage. ISPRS Int. J. Geo-Inf. 6 , 132 (2017). Article Google Scholar Yin, H., Zhang, Z. & Liu, Y. The exploration of integrating the Midjourney artificial-intelligence generated content tool into design systems to direct designers towards future-oriented innovation. Systems 11 , 566 (2023). Article Google Scholar Xu, C., Du, X. & Yu, K. Challenges and Strategies of AIGC in the Design Industry(in Chinese). Artif. Intell. 4 , 51–60 (2023). Google Scholar Lei, T. et al. Digital Protection and Virtual Display of Ancient Architectural Murals in Hancheng, Shaanxi Based on Edge Computing and AI Technology. International Journal of High Speed Electronics and Systems, 2540518. (2025). Yazdani, S. Virtual reconstruction and preservation of heritage sites using historical building information modelling (HBIM) through a case study (MSc dissertation). University of Strathclyde, Glasgow, UK. (2024). Zhang, C., Deng, K., Yan, D., Mao, J. & Yang, X. Research on Multi-Source Image Fusion Technology in the Digital Reconstruction of Classical Garden and Ancient Buildings. Int. Rev. Spat. Plan Sustain. Dev. 11 , 116–116 (2023). Google Scholar Yang, X. et al. Review of built heritage modelling: integration of HBIM and other information techniques. J. Cult. Herit. 46 , 350–360 (2020). Article Google Scholar López, F. J., Lerones, P. M., Llamas, J., Gómez-García-Bermejo, J. & Zalama, E. A Review of Heritage Building Information Modeling (H-BIM). Multimodal Technol. Interact. 2 , 21 (2018). Article Google Scholar Oumoumen, K., Aboubane, F. & Ech-Charqy, Y. Automation of historical buildings: historical building information modeling (HBIM) based virtual reality (VR). Mater. Res. Proc. Mediterranean Architectural Herit. 40 , 319–322 (2024). Article Google Scholar Sukkar, A. W. et al. Analytical evaluation of MidJourney architectural virtual lab: defining major current limits in AI-generated representations of Islamic architectural heritage. Buildings 14 , 786 (2024). Article Google Scholar Yang, X. et al. Review of built heritage modelling: Integration of HBIM and VI. J. Cult. Herit. 42 , 200–212 (2020). Google Scholar Li, D. Yangzhou huafang lu [Yangzhou Sketches From the Paint-Boat]. (ed. Chen, W.). Vol. 4, 288–352 (Yangzhou: Guangling Publishing House, 2010). (In Chinese). Download references Acknowledgements The Innovation Team Project of Henan Academy of Sciences (Grant No. 20230103). The Research Start-up (R&D) Project of the Henan Academy of Sciences Project (Grant No. 241801094). Author information Authors and Affiliations Institute of Geographical Sciences, Henan Academy of Sciences, Zhengzhou, Henan, China Changqing Wei, Dongyi Kong, Yang Wang, Jing Jia, Jiaru Liu & Yan Wei Authors Changqing Wei View author publications Search author on: PubMed Google Scholar Dongyi Kong View author publications Search author on: PubMed Google Scholar Yang Wang View author publications Search author on: PubMed Google Scholar Jing Jia View author publications Search author on: PubMed Google Scholar Jiaru Liu View author publications Search author on: PubMed Google Scholar Yan Wei View author publications Search author on: PubMed Google Scholar Contributions Changqing W. and Dongyi K. wrote the main manuscript. Yang W. and Changqing W. conducted the surveying work, performed image generation with AIGC tools, and carried out data analysis. Changqing W. and Jiaru L. prepared all figures. Jing J. and Yan W. reviewed and edited the manuscript. All authors read and approved the final version of the manuscript. Corresponding author Correspondence to Dongyi Kong . Ethics declarations Competing interests The authors declare no competing interests. Additional information Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by-nc-nd/4.0/ . Reprints and permissions About this article Cite this article Wei, C., Kong, D., Wang, Y. et al. AIGC based digital heritage reconstruction of Qing interior canopies. npj Herit. Sci. 14 , 71 (2026). https://doi.org/10.1038/s40494-025-02280-y Download citation Received : 05 September 2025 Accepted : 20 December 2025 Published : 30 January 2026 Version of record : 30 January 2026 DOI : https://doi.org/10.1038/s40494-025-02280-y Share this article Anyone you share the following link with will be able to read this content: Get shareable link Sorry, a shareable link is not currently available for this article. Copy shareable link to clipboard Provided by the Springer Nature SharedIt content-sharing initiative"
}