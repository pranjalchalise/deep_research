{
  "metadata": {
    "key": "page:https://www.amazon.science/publications/vera-validation-and-evaluation-of-retrieval-augmented-systems",
    "created": 1769979835.543465,
    "ttl": 604800
  },
  "data": "Publication VERA: Validation and evaluation of retrieval-augmented systems By Terry Ding , Adi Banerjee , Mabel Li , Laurent Mombaerts , Tarik Borogovac , Juan Pablo De la Cruz Weinstein 2024 Download Copy BibTeX @Article{Ding2024, author = {Terry Ding and Adi Banerjee and Mabel Li and Laurent Mombaerts and Tarik Borogovac and Juan Pablo De la Cruz Weinstein}, title = {VERA: Validation and evaluation of retrieval-augmented systems}, year = {2024}, url = {https://www.amazon.science/publications/vera-validation-and-evaluation-of-retrieval-augmented-systems}, } Share Share Copy link Email X LinkedIn Facebook Line Reddit QZone Sina Weibo WeChat WhatsApp 分享到微信 x Download Copy BibTeX @Article{Ding2024, author = {Terry Ding and Adi Banerjee and Mabel Li and Laurent Mombaerts and Tarik Borogovac and Juan Pablo De la Cruz Weinstein}, title = {VERA: Validation and evaluation of retrieval-augmented systems}, year = {2024}, url = {https://www.amazon.science/publications/vera-validation-and-evaluation-of-retrieval-augmented-systems}, } Share Share Copy link Email X LinkedIn Facebook Line Reddit QZone Sina Weibo WeChat WhatsApp 分享到微信 x The increasing use of Retrieval-Augmented Generation (RAG) systems in various applications necessitates stringent protocols to ensure RAG systems’ accuracy, safety, and alignment with user intentions. In this paper, we introduce VERA (Validation and Evaluation of Retrieval-Augmented Systems), a framework designed to enhance the transparency and reliability of outputs from large language models (LLMs) that utilize retrieved information. VERA improves the way we evaluate RAG systems in two important ways:(1) it introduces a cross-encoder based mechanism that encompasses a set of multidimensional metrics into a single comprehensive rank-ing score, addressing the challenge of prioritizing individual metrics, and (2) it employs Bootstrap statistics on LLM-based metrics across the document repository to establish confidence bounds, ensuring the repository’s topical coverage and improving the overall reliability of retrieval systems. Through several use cases, we demonstrate how VERA can strengthen decision-making processes and trust in AI applications. Our findings not only contribute to the theoretical understanding of LLM-based RAG evaluation metric but also promote the practical implementation of responsible AI systems, marking a significant advancement in the development of reliable and transparent generative AI technologies. Research areas Conversational AI Tags Large language models (LLMs) Retrieval-augmented generation (RAG)"
}