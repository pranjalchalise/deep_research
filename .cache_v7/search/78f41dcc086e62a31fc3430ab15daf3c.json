{
  "metadata": {
    "key": "search:general:6:\"langchain\" How are the new features defined?",
    "created": 1770002897.472814,
    "ttl": 86400
  },
  "data": [
    {
      "url": "https://cloud.google.com/use-cases/langchain",
      "title": "What Is LangChain? Examples and definition - Google Cloud",
      "snippet": "This chaining approach lets developers define a sequence of actions their application will take to handle a user's request and create a response. By simplifying these steps into components, LangChain makes it easier to build applications that need multiple interactions with an LLM or external resources. The framework also offers ways to work with different LLMs, giving developers the freedom to choose the best model for their specific application.\n\nLearn more about how you can use LangChain with Vertex AI.\n\n## Key features of LangChain\n\nLangChain provides a suite of features designed to facilitate the development of LLM-powered applications. These features are organized around core concepts that help manage interactions with models, connect to data, and orchestrate complex behaviors. [...] # What is LangChain?\n\nLangChain is an open-source orchestration framework that simplifies building applications with large language models (LLMs). It provides tools and components to connect LLMs with various data sources, enabling the creation of complex, multi-step workflows.\n\nAvailable as libraries in Python and JavaScript, LangChain helps developers enhance LLM capabilities beyond text generation by linking them to external data and computation. This helps facilitate the development of advanced AI applications like intelligent chatbots, sophisticated question-answering systems, and automated data analysis tools.\n\nGet started for free\n\nBuild AI-powered apps on Vertex AI with LangChain\n\n# LangChain and AI [...] ## How does LangChain work?\n\nLangChain works by \"chaining\" together different components to create a cohesive workflow for LLM-powered applications. This modular approach breaks down complex language-based AI systems into reusable parts. When a user submits a query, LangChain can process this input through a series of steps.\n\nFor example, a typical workflow might involve:"
    },
    {
      "url": "https://docs.langchain.com/oss/python/releases/langchain-v1",
      "title": "What's new in LangChain v1",
      "snippet": "create_agent ------------ The new standard for building agents in LangChain, replacing `langgraph.prebuilt.create_react_agent`.Standard content blocks ----------------------- A new `content_blocks` property that provides unified access to modern LLM features across providers.Simplified namespace -------------------- The `langchain` namespace has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to `langchain-classic`.\n\nTo upgrade,\n\npip\n\nuv\n\nCopy\n\n```\npip install -U langchain\n```\n\nFor a complete list of changes, see the migration guide.\nâ€‹\n\n`create_agent` [...] â€‹\n\nSimplified package\n\nLangChain v1 streamlines the `langchain` package namespace to focus on essential building blocks for agents. The refined namespace exposes the most useful and relevant functionality:\n### â€‹\n\nNamespace\n\n| Module | Whatâ€™s available | Notes |\n --- \n| `langchain.agents` | `create_agent`, `AgentState` | Core agent creation functionality |\n| `langchain.messages` | Message types, content blocks, `trim_messages` | Re-exported from `langchain-core` |\n| `langchain.tools` | `@tool`, `BaseTool`, injection helpers | Re-exported from `langchain-core` |\n| `langchain.chat_models` | `init_chat_model`, `BaseChatModel` | Unified model initialization |\n| `langchain.embeddings` | `Embeddings`, `init_embeddings` | Embedding models | [...] Structured output\n\n`create_agent` has improved structured output generation:\n   Main loop integration: Structured output is now generated in the main loop instead of requiring an additional LLM call\n   Structured output strategy: Models can choose between calling tools or using provider-side structured output generation\n   Cost reduction: Eliminates extra expense from additional LLM calls\n\nCopy\n\n```\nfrom langchain.agents import create_agent\nfrom langchain.agents.structured_output import ToolStrategy\nfrom pydantic import BaseModel\n\nclass Weather(BaseModel):\n    temperature: float\n    condition: str\n\ndef weather_tool(city: str) -> str:\n    \"\"\"Get the weather for a city.\"\"\"\n    return f\"it's sunny and 70 degrees in {city}\""
    },
    {
      "url": "https://docs.langchain.com/oss/javascript/releases/langchain-v1",
      "title": "What's new in LangChain v1",
      "snippet": "createAgent ----------- A new standard way to build agents in LangChain, replacing `createReactAgent` from LangGraph with a cleaner, more powerful API.Standard content blocks ----------------------- A new `contentBlocks` property that provides unified access to modern LLM features across all providers.Simplified package ------------------ The `langchain` package has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to `@langchain/classic`.\n\nTo upgrade,\n\nnpm\n\npnpm\n\nyarn\n\nbun\n\nCopy\n\n```\nnpm install langchain @langchain/core\n```\n\nFor a complete list of changes, see the migration guide.\nâ€‹\n\n`createAgent` [...] ### â€‹\n\nBenefits\n\n   Provider agnostic: Access reasoning traces, citations, built-in tools (web search, code interpreters, etc.), and other features using the same API regardless of provider\n   Type safe: Full type hints for all content block types\n   Backward compatible: Standard content can be loaded lazily, so there are no associated breaking changes\n\nFor more information, see our guide on content blocks\n\n  \n\nâ€‹\n\nSimplified package\n\nLangChain v1 streamlines the `langchain` package namespace to focus on essential building blocks for agents. The package exposes only the most useful and relevant functionality:Most of these are re-exported from `@langchain/core` for convenience, which gives you a focused API surface for building agents.\n### â€‹\n\n`@langchain/classic` [...] Structured output\n\n`createAgent` has improved structured output generation:\n   Main loop integration: Structured output is now generated in the main loop instead of requiring an additional LLM call\n   Structured output strategy: Models can choose between calling tools or using provider-side structured output generation\n   Cost reduction: Eliminates extra expense from additional LLM calls\n\nCopy\n\n```\nimport { createAgent } from \"langchain\";\nimport  as z from \"zod\";\n\nconst weatherSchema = z.object({\n  temperature: z.number(),\n  condition: z.string(),\n});\n\nconst agent = createAgent({\n  model: \"gpt-4o-mini\",\n  tools: [getWeather],\n  responseFormat: weatherSchema,\n});\n\nconst result = await agent.invoke({\n  messages: [\n    { role: \"user\", content: \"What is the weather in Tokyo?\" },\n  ],\n});"
    },
    {
      "url": "https://focused.io/lab/langchain-under-the-hood-5-features-we-rely-on-daily",
      "title": "LangChain Under the Hood: 5 Features We Rely On Daily | Focused",
      "snippet": "## Bonus: LLMs That Take Action with Tool Calling\n\nLangChain's tool system allows LLMs to call external functions and APIs. Tools transform LLMs from text generators into action-taking agents that can interact with external systems. In LangChain, tools are declared using the @tool decorator which is used to associate a function with a schema that defines the functionâ€™s name, description and expected arguments. We can then bind the tool to an LLM so that it has the tool at its disposal. Given a request, the LLM decides whether or not it needs to call a tool it has in its toolbox to satisfy the request and how the call(s) should be structured according to the tool schema.\n\nLetâ€™s supercharge our research assistant with the ability to search for the latest LangChain news. [...] ## Bonus: LLMs That Take Action with Tool Calling\n\nLangChain's tool system allows LLMs to call external functions and APIs. Tools transform LLMs from text generators into action-taking agents that can interact with external systems. In LangChain, tools are declared using the @tool decorator which is used to associate a function with a schema that defines the functionâ€™s name, description and expected arguments. We can then bind the tool to an LLM so that it has the tool at its disposal. Given a request, the LLM decides whether or not it needs to call a tool it has in its toolbox to satisfy the request and how the call(s) should be structured according to the tool schema.\n\nLetâ€™s supercharge our research assistant with the ability to search for the latest LangChain news. [...] ## Bonus: LLMs That Take Action with Tool Calling\n\nLangChain's tool system allows LLMs to call external functions and APIs. Tools transform LLMs from text generators into action-taking agents that can interact with external systems. In LangChain, tools are declared using the @tool decorator which is used to associate a function with a schema that defines the functionâ€™s name, description and expected arguments. We can then bind the tool to an LLM so that it has the tool at its disposal. Given a request, the LLM decides whether or not it needs to call a tool it has in its toolbox to satisfy the request and how the call(s) should be structured according to the tool schema.\n\nLetâ€™s supercharge our research assistant with the ability to search for the latest LangChain news."
    },
    {
      "url": "https://medium.com/mitb-for-all/langchain-a-second-look-6ed720e27fec",
      "title": "LangChain 1.0 â€” A second look - Medium",
      "snippet": "LangChain has good callback handlers defined as well â€” Iâ€™ve added LangChainâ€™s default `UsageMetadataCallbackHandler` as an LLM callback above. This allows us to quickly access usage metadata by:\n\n```\nprint(usage_callback.usage_metadata)\n```\n\n## ðŸ§  Agents\n\nThis is one of the biggest changes.\n\nFrom LangChain 1.0 onwards, the only way to define an agent is within LangChain itself, not LangGraph. The older ways of defining agents â€” through Agent and AgentExecutor â€” are officially deprecated. (And honestly, I wonâ€™t miss them either.)\n\nInstead, itâ€™s now refreshingly simple:\n\n```\nfrom langchain.agents import create_agentagent = create_agent(llm, tools)\n``` [...] LangChain 1.0 is a vast improvement over the 0.3 LangChain frameworks â€” it is a comprehensive rewrite with many new, meaningful features. LangGraph 1.0 is a modest yet meaningful improvement, deliberately re-designed to fit better with LangChain 1.0.\n\nTo keep this article digestible, Iâ€™ll cover only the meaningful improvements (there are many) of the LangChain 1.0 framework. Iâ€™ll probably cover the LangGraph 1.0 framework in a separate article.\n\nAs always, all codes can be found in my GitHub repository.\n\n## TLDR: The core changes at a high level\n\nIâ€™ve identified two main core changes:\n\n### Context engineering [...] LangChain now allows us to batch invoke an LLM:\n\n```\nquestions = [ \"How can quantum computing be used together with generative AI to develop new algorithms for drug discovery?\", \"How do you think we can save the world from climate change?\", \"What are the ethical implications of using AI in healthcare?\",]responses = llm.batch(questions)for response in responses: print(response)\n```\n\nThe `batch` method allows us to send multiple questions concurrently. But this method will only return the output once all the responses are collected. To receive individual outputs as it is done:\n\n```\nfor response in llm.batch_as_completed(questions): print(response)\n```\n\nThe way to stream and use an LLM to return structured outputs is unchanged.\n\n### Callbacks and Configs â€” extra settings"
    },
    {
      "url": "https://www.youtube.com/watch?v=x0W2ZbWDQmE",
      "title": "LangChain Overview for Beginners! [Updated 2026] - YouTube",
      "snippet": "models and uh uh lang chain can be defined with two different words I mean like two words that lang chain is made up of lang comes from the large language bottles which is the llms and chain refers to the concept of how basically lang chain works like uh you you know chaining together different components into workflows. Okay guys, so we understood the meaning of lang chain how lang chain can be uh subdivided into two parts that is lang and chain. What is the literal meaning of lang chain? We saw and uh now um we are seeing the lang chain components. So these are the main components of lang chain. Um there are six components that uh actually make lang chain so powerful. Uh as you can see there are LLMs. So lagchain is a platform that will basically help you connect connect all these [...] logic or systems. That's the main these are some of the main limitations. So LMS are not just enough. Why? What we require? We require uh robust LLM frameworks like lang chain and llama index. Since this video is all about lang chain. So I'm going to just talk about lang chain. So lang chain was developed by Harrison [snorts] chase uh which came out in October 2022. It's all it's been almost 4 years and uh lang chain serves as an open-source platform to help developers build hello empowered applications. As you can see in the image right you can connect with any data sources structured unstructured data source. um you can have word embeddings and uh you can connect with any vector database and also to any uh LLMs or language language models and uh uh lang chain can be defined with two [...] different scenarios right so uh if you're building an AI application or a chat application you can basically build it like as if um you are building it for a 5-year-old. So your all the responses from your application um you know will be as if they are for a 5-year-old. So you can define these templates basically. So these are the main components of lang chain and uh yeah I was just going through the uh lang chain how it is growing. I went to Google trends just to search for this keyword lang chain. As you can see from 2023 uh it started growing. I mean like 2022 uh on October it came out but many people didn't know how to use lang why to use lang chain uh but then slowly uh the community grew and people started liking langchain and started using lang chain for to build their a"
    }
  ]
}