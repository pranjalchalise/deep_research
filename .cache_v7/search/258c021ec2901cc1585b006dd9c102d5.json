{
  "metadata": {
    "key": "search:general:6:Retrieval Augmented Generation (RAG) in project management and its applications",
    "created": 1769986482.9291751,
    "ttl": 86400
  },
  "data": [
    {
      "url": "https://www.databricks.com/glossary/retrieval-augmented-generation-rag",
      "title": "What is Retrieval Augmented Generation (RAG)? - Databricks",
      "snippet": "## What Is Retrieval Augmented Generation, or RAG?\n\nRetrieval augmented generation (RAG) is a hybrid AI framework that bolsters large language models (LLMs) by combining them with external, up-to-date data sources. Instead of relying solely on static training data, RAG retrieves relevant documents at query time and feeds them into the model as context. By incorporating new and context-aware data, AI can generate more accurate, current and domain-specific responses.\n\nRAG is quickly becoming the go-to architecture for building enterprise-grade AI applications. According to recent surveys, over 60% of organizations are developing AI-powered retrieval tools to improve reliability, reduce hallucinations and personalize outputs using internal data. [...] 1. Prepare data: Document data is gathered alongside metadata and subjected to initial preprocessing ‚Äî for example, PII handling (detection, filtering, redaction, substitution). To be used in RAG applications, documents need to be chunked into appropriate lengths based on the choice of embedding model and the downstream LLM application that uses these documents as context.\n2. Index relevant data: Produce document embeddings and hydrate a Vector Search index with this data.\n3. Retrieve relevant data: Retrieving parts of your data that are relevant to a user's query. That text data is then provided as part of the prompt that is used for the LLM. [...] ## Frequently asked questions (FAQ)\n\nWhat is retrieval augmented generation (RAG)?  \nRAG is an AI architecture that strengthens LLMs by retrieving relevant documents and injecting them into the prompt. This enables more accurate, current and domain-specific responses without taking time to retrain the model.\n\nWhen should I use RAG instead of fine-tuning?  \nUse RAG when you want to incorporate dynamic data without the cost or complexity of fine-tuning. It is ideal for use cases where accurate and timely information is required."
    },
    {
      "url": "https://github.com/Danielskry/Awesome-RAG",
      "title": "Awesome list of Retrieval-Augmented Generation (RAG ... - GitHub",
      "snippet": "LangFuse: Open-source tool for tracking LLM metrics, observability, and prompt management.\n Ragas: Framework that helps evaluate RAG pipelines.\n LangSmith: A platform for building production-grade LLM applications, allows you to closely monitor and evaluate your application.\n Hugging Face Evaluate: Tool for computing metrics like BLEU and ROUGE to assess text quality.\n Weights & Biases: Tracks experiments, logs metrics, and visualizes performance.\n\n## üíæ Databases\n\nThe list below features several database systems suitable for Retrieval Augmented Generation (RAG) applications. They cover a range of RAG use cases, aiding in the efficient storage and retrieval of vectors to generate responses or recommendations.\n\n Picking a vector database [...] 896 stars   61 forks   Branches   Tags   Activity\n\nStar\n\nNotifications  You must be signed in to change notification settings\n\n# Danielskry/Awesome-RAG\n\nBranchesTags\n\nOpen more actions menu\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n ---  --- |\n| Latest commit   History71 Commits |\n| LICENSE | LICENSE |  |  |\n| README.md | README.md |  |  |\n|  |\n\n## Repository files navigation\n\n# üòé Awesome Retrieval Augmented Generation (RAG)\n\nThis repository contains a curated Awesome List and general information on Retrieval-Augmented Generation (RAG) applications in Generative AI. [...] Retrieval-Augmented Generation (RAG) is a technique in Generative AI where additional context is retrieved from external sources to enrich the generative process of Large Language Models (LLMs). This approach allows LLMs to incorporate up-to-date, specific, or sensitive information that they may lack from their pre-training data alone.\n\n## Content\n\n ‚ÑπÔ∏è General Information on RAG\n üéØ Approaches\n üß∞ Frameworks that Facilitate RAG\n üõ†Ô∏è Techniques\n üìä Metrics\n üíæ Databases\n\n## ‚ÑπÔ∏è General Information on RAG"
    },
    {
      "url": "https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts",
      "title": "Retrieval Augmented Generation (RAG) and Semantic Search for ...",
      "snippet": "# Retrieval Augmented Generation (RAG) and Semantic Search for GPTs\n\nLearn about RAG and how it is useful to GPT builders\n\nUpdated: 16 days ago\n\n## What is Retrieval Augmented Generation (RAG), and why is it valuable for GPT builders?\n\nRetrieval Augmented Generation (RAG) is a technique that improves a model‚Äôs responses by injecting external context into its prompt at runtime. Instead of relying solely on the model‚Äôs pre-trained knowledge, RAG retrieves relevant information from connected data sources and uses it to generate a more accurate and context-aware response.\n\nIn GPTs, RAG is performed automatically when knowledge retrieval is enabled and files have been uploaded. The model dynamically retrieves relevant information from those files to supplement the user‚Äôs prompt."
    },
    {
      "url": "https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview",
      "title": "RAG and generative AI - Azure AI Search - Microsoft Learn",
      "snippet": "Skip to Ask Learn chat experience \n\nThis browser is no longer supported.\n\nUpgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.\n\nDownload Microsoft Edge   More info about Internet Explorer and Microsoft Edge\n\nRead in English   Edit  \n\n#### Share via\n\n Facebook   x.com   LinkedIn   Email  \n\n---\n\nAccess to this page requires authorization. You can try signing in or changing directories.\n\nAccess to this page requires authorization. You can try changing directories.\n\n# Retrieval-augmented Generation (RAG) in Azure AI Search\n\nRetrieval-augmented Generation (RAG) is a pattern that extends LLM capabilities by grounding responses in your proprietary content. While conceptually simple, RAG implementations face significant challenges."
    },
    {
      "url": "https://www.redhat.com/en/blog/redefining-development-retrieval-augmented-generation-rag-revolution-software-engineering",
      "title": "Redefining development: The retrieval-augmented generation (RAG ...",
      "snippet": "Share\n\nSubscribe to RSS\n\n Back to all posts\n\nOne of the latest advancements in natural language processing (NLP) is retrieval-augmented generation (RAG), a technique that combines the strengths of information retrieval and natural language generation (NLG). RAG can reshape how software is conceptualized, designed and implemented, ushering in a new era of efficiency and creativity powered by generative models.\n\n## What is retrieval-augmented generation (RAG)?\n\nRetrieval-augmented generation (RAG) is a natural language processing (NLP) model that combines two key components: a generator and a retriever.\n\nGenerator: This part creates new content, such as sentences or paragraphs, usually based on large language models (LLMs). [...] Retriever: This part retrieves relevant information from a predetermined set of documents or data.\n\nIn simple terms, RAG uses the retriever to find useful information from a vast collection of texts, and then the generator uses that information to augment its LLM-based training to create new, coherent text. This approach helps improve the quality and relevance of AI-generated content by leveraging new and often more domain-specific knowledge outside of the vast dataset used to train the original LLM. It's commonly used in tasks like answering questions or summarizing text.\n\nRAG integrates these two processes, allowing developers to use a wealth of existing knowledge to augment LLMs to enhance the generation of new, contextually relevant content.\n\n### What does the data look like? [...] ### Data and documentation\n\nRAG can be used to retrieve relevant data from both on-prem and cloud-based data sources. This is particularly useful in a hybrid cloud environment where data may be distributed across multiple locations. By more effectively retrieving and augmenting data, MLOps helps machine learning models access diverse and comprehensive datasets for training and validation.\n\nRAG can also aid in automating documentation and knowledge-sharing processes within MLOps workflows. RAG systems can automatically generate documentation, reports and summaries of machine learning experiments, model evaluations and deployment procedures using NLG capabilities. This helps maintain comprehensive activity records and simplifies knowledge transfer between team members."
    },
    {
      "url": "https://cloud.google.com/use-cases/retrieval-augmented-generation",
      "title": "What is Retrieval-Augmented Generation (RAG)? - Google Cloud",
      "snippet": "Developer Tools\n\n Artifact Registry\n\n  Universal package manager for build artifacts and dependencies.\n\n Cloud Code\n\n  IDE support to write, run, and debug Kubernetes applications.\n\n Cloud Build\n\n  Continuous integration and continuous delivery platform.\n\n Cloud Deploy\n\n  Fully managed continuous delivery to GKE and Cloud Run.\n\n Cloud Deployment Manager\n\n  Service for creating and managing Google Cloud resources.\n\n Cloud SDK\n\n  Command-line tools and libraries for Google Cloud.\n\n Cloud Scheduler\n\n  Cron job scheduler for task automation and management.\n\n Cloud Source Repositories\n\n  Private Git repository to store, manage, and track code.\n\n Infrastructure Manager\n\n  Automate infrastructure management with Terraform.\n\n Cloud Workstations [...] Artifact Registry\n\n  Package manager for build artifacts and dependencies.\n\n Cloud Code\n\n  IDE support to write, run, and debug Kubernetes applications.\n\n Cloud Deploy\n\n  Fully managed continuous delivery to GKE and Cloud Run.\n\n Migrate to Containers\n\n  Components for migrating VMs into system containers on GKE.\n\n Deep Learning Containers\n\n  Containers with data science frameworks, libraries, and tools.\n\n Knative\n\n  Components to create Kubernetes-native cloud-based software.\n\n Data Analytics\n\n BigQuery\n\n  Autonomous data to AI platform for analytics and data science.\n\n Looker\n\n  Platform for BI, data applications, and embedded analytics.\n\n Dataflow\n\n  Real-time analytics for stream and batch processing.\n\n Pub/Sub\n\n  Messaging service for event ingestion and delivery.\n\n Dataproc [...] Cost Management\n\n  Tools for monitoring, controlling, and optimizing your costs.\n\n Observability\n\n  Monitoring, logging, and application performance suite.\n\n Carbon Footprint\n\n  Dashboard to view and export Google Cloud carbon emissions reports.\n\n Config Connector\n\n  Kubernetes add-on for managing Google Cloud resources.\n\n Active Assist\n\n  Tools for easily managing performance, security, and cost.\n\n Not seeing what you're looking for?\n See all management tools\n\n Maps and Geospatial\n\n Earth Engine\n\n  Geospatial platform for Earth observation data and analysis.\n\n Google Maps Platform\n\n  Create immersive location experiences and improve business operations.\n\n Media Services\n\n Cloud CDN\n\n  Content delivery network for serving web and video content.\n\n Live Stream API"
    }
  ]
}