{
  "metadata": {
    "key": "search:general:6:RAG methodology in data science applications",
    "created": 1769979947.982274,
    "ttl": 86400
  },
  "data": [
    {
      "url": "https://www.databricks.com/glossary/retrieval-augmented-generation-rag",
      "title": "What is Retrieval Augmented Generation (RAG)? - Databricks",
      "snippet": "## What Is Retrieval Augmented Generation, or RAG?\n\nRetrieval augmented generation (RAG) is a hybrid AI framework that bolsters large language models (LLMs) by combining them with external, up-to-date data sources. Instead of relying solely on static training data, RAG retrieves relevant documents at query time and feeds them into the model as context. By incorporating new and context-aware data, AI can generate more accurate, current and domain-specific responses.\n\nRAG is quickly becoming the go-to architecture for building enterprise-grade AI applications. According to recent surveys, over 60% of organizations are developing AI-powered retrieval tools to improve reliability, reduce hallucinations and personalize outputs using internal data. [...] 1. Prepare data: Document data is gathered alongside metadata and subjected to initial preprocessing ‚Äî for example, PII handling (detection, filtering, redaction, substitution). To be used in RAG applications, documents need to be chunked into appropriate lengths based on the choice of embedding model and the downstream LLM application that uses these documents as context.\n2. Index relevant data: Produce document embeddings and hydrate a Vector Search index with this data.\n3. Retrieve relevant data: Retrieving parts of your data that are relevant to a user's query. That text data is then provided as part of the prompt that is used for the LLM. [...] As generative AI expands into business functions like customer service, internal knowledge management and compliance, RAG‚Äôs ability to bridge the gap between general AI and specific organizational knowledge makes it an essential foundation for trustworthy, real-world deployments.\n\nHere‚Äôs more to explore\n\nThe Big Book of MLOps\n\nA must-read for ML engineers and data scientists seeking a better way to do MLOps.\n\nGet the eBook\n\nAugment your LLM's using RAG\n\nHow to get more from generative AI with RAG.\n\nDownload now\n\nDatabricks ranked #1 in Execution and Vision\n\n2025 Gartner Magic Quadrant‚Ñ¢ for Data Science and Machine Learning Platforms.\n\nRead now\n\n## How RAG works"
    },
    {
      "url": "https://www.projectpro.io/article/retrieval-augmented-generation-projects-and-examples/973",
      "title": "9 Retrieval Augmented Generation Project Ideas for Practice",
      "snippet": "Creating a text summarization app using Retrieval-Augmented Generation (RAG) involves a few steps. First, it's essential to build a system that can fetch relevant data from different sources like databases or documents with the help of data science libraries such as BeautifulSoup. This data is then converted into a form that's easy to search and use. RAG works by combining the user's query with additional context retrieved from external sources to create a more detailed prompt. This augmented prompt is then fed into a language model that generates concise and informative summaries. The process keeps evolving by updating the knowledge base and how the system understands text, ensuring the app keeps getting better at summarizing text.\n\n1. ### Web-Based Doc Summarization Bot using ChatGroq [...] 1. ### fastRAG\n\nfastRAG is a pioneering research framework that integrates cutting-edge Large Language Models (LLMs) and Information Retrieval to refine retrieval-augmented-generative pipelines. It empowers data scientists and researchers by offering a comprehensive toolkit, resulting in advancements in this innovative fusion of retrieval and generation methodologies. Its recent updates have introduced substantial enhancements, such as support for Gaudi2, ONNX runtime, and LlamaCPP, alongside optimized embedding models and multi-modality and chat demos, including REPLUG text generation. [...] Start Project\n\nRetrieval-augmented-generation (RAG) is a fascinating approach in natural language processing that combines the strengths of retrieval-based and generation-based models. It's designed to enhance the capabilities of language models by incorporating a retriever module that can access and retrieve relevant information from a large external knowledge source, like a database or a collection of documents. The primary reason for its popularity is best highlighted in this post by Abhishek Ratna."
    },
    {
      "url": "https://medium.com/data-science/evaluating-rag-applications-with-ragas-81d67b0ee31a",
      "title": "Evaluating RAG Applications with RAGAs - Medium",
      "snippet": "Sitemap\n\nOpen in app\n\nSign in\n\nSign in\n\n## TDS Archive\n\nAn archive of data science, data analytics, data engineering, machine learning, and artificial intelligence writing from the former Towards Data Science Medium publication.\n\n# Evaluating RAG Applications with RAGAs\n\n## A framework with metrics and LLM-generated data to evaluate the performance of your Retrieval-Augmented Generation pipeline\n\nLeonie Monigatti\n\n8 min read\n\n¬∑\n\nDec 13, 2023\n\n--\n\nBy now, we know that building a proof of concept for a Retrieval-Augmented Generation (RAG) application is easy, but making it production-ready is very difficult. Getting the RAG pipeline's performance to a satisfying state is especially difficult because of the different components in a RAG pipeline: [...] Additionally, define your relevant environment variables in a .env file in your root directory. To obtain an OpenAI API Key, you need an OpenAI account and then ‚ÄúCreate new secret key‚Äù under API keys.\n\n```\nOPENAI_API_KEY=\"\"\n```\n\n### Setting up the RAG application\n\nBefore you can evaluate your RAG application, you need to set it up. We will use a vanilla RAG pipeline. We will keep this section short since we will use the same setup described in detail in the following article.\n\n## Retrieval-Augmented Generation (RAG): From Theory to LangChain Implementation\n\n### From the theory of the original academic paper to its Python implementation with OpenAI, Weaviate, and LangChain\n\ntowardsdatascience.com\n\nFirst, you must prepare the data by loading and chunking the documents. [...] Wang, P., Li, L., Chen, L., Zhu, D., Lin, B., Cao, Y., ‚Ä¶ & Sui, Z. (2023). Large language models are not fair evaluators. arXiv preprint arXiv:2305.17926.\n\n Liu, Y., Iter, D., Xu, Y., Wang, S., Xu, R., & Zhu, C. (2023). G-eval: Nlg evaluation using gpt-4 with better human alignment, may 2023. arXiv preprint arXiv:2303.16634, 6.\n\n### Images\n\nIf not otherwise stated, all images are created by the author.\n\nData Science\n\nMachine Learning\n\nArtificial Intelligence\n\nProgramming\n\nRags\n\n## Published in TDS Archive\n\n828K followers\n\n¬∑Last published Feb 3, 2025\n\nAn archive of data science, data analytics, data engineering, machine learning, and artificial intelligence writing from the former Towards Data Science Medium publication.\n\n## Written by Leonie Monigatti\n\n33K followers\n\n¬∑184 following"
    },
    {
      "url": "https://www.ibm.com/think/topics/retrieval-augmented-generation",
      "title": "What is RAG (Retrieval Augmented Generation)? - IBM",
      "snippet": "# What is retrieval augmented generation (RAG)?\n\n## What is retrieval augmented generation (RAG)?\n\nRetrieval augmented generation, or RAG, is an architecture for optimizing the performance of an artificial intelligence (AI) model by connecting it with external knowledge bases. RAG helps large language models (LLMs) deliver more relevant responses at a higher quality.\n\nGenerative AI (gen AI) models are trained on large datasets and refer to this information to generate outputs. However, training datasets are finite and limited to the information the AI developer can access‚Äîpublic domain works, internet articles, social media content and other publicly accessible data. [...] Register now\n\nTutorial   IBM Developer: RAG tutorials \n\nExplore all IBM Developer retrieval augmented generation (RAG) tutorials.\n\n Start learning\n\nTechsplainers Podcast   Retrieval augmented generation (RAG) explained \n\nTechsplainers by IBM breaks down the essentials of RAG, from key concepts to real‚Äëworld use cases. Clear, quick episodes help you learn the fundamentals fast.\n\n Listen now\n\nReport   IBM is named a leader in data science and machine learning \n\nLearn why IBM has been recognized as a leader in the 2025 Gartner¬Æ Magic Quadrant‚Ñ¢ for Data Science and Machine Learning Platforms.\n\n Read the report\n\nBlog   IBM RAG Cookbook \n\nExplore a comprehensive collection of best practices, considerations and tips for building RAG solutions tailored to business applications.\n\n Read the blog [...] ### Enhanced developer control and model maintenance\n\nModern organizations constantly process massive quantities of data, from order inputs to market projections to employee turnover and more. Effective data pipeline construction and data storage is paramount for strong RAG implementation.\n\nAt the same time, developers and data scientists can tweak the data sources to which models have access at any time. Repositioning a model from one task to another becomes a task of adjusting its external knowledge sources as opposed to fine-tuning or retraining. If fine-tuning is needed, developers can prioritize that work instead of managing the model‚Äôs data sources.\n\n### Greater data security"
    },
    {
      "url": "https://github.com/Danielskry/Awesome-RAG",
      "title": "Awesome list of Retrieval-Augmented Generation (RAG ... - GitHub",
      "snippet": "Retrieval-Augmented Generation (RAG) is a technique in Generative AI where additional context is retrieved from external sources to enrich the generative process of Large Language Models (LLMs). This approach allows LLMs to incorporate up-to-date, specific, or sensitive information that they may lack from their pre-training data alone.\n\n## Content\n\n ‚ÑπÔ∏è General Information on RAG\n üéØ Approaches\n üß∞ Frameworks that Facilitate RAG\n üõ†Ô∏è Techniques\n üìä Metrics\n üíæ Databases\n\n## ‚ÑπÔ∏è General Information on RAG [...] RAG Fusion: Techniques combining multiple retrieval methods for improved context integration.\n Temporal Augmented Retrieval (TAR): Considering time-sensitive data in retrieval processes.\n Plan-then-RAG (PlanRAG): Strategies involving planning stages before executing RAG for complex tasks.\n GraphRAG: A structured approach using knowledge graphs for enhanced context integration and reasoning.\n FLARE - An approach that incorporates active retrieval-augmented generation to improve response quality.\n GNN-RAG: Graph neural retrieval for large language modeling reasoning.\n Multimodal RAG: Extends RAG to handle multiple modalities such as text, images, and audio. [...] LangFuse: Open-source tool for tracking LLM metrics, observability, and prompt management.\n Ragas: Framework that helps evaluate RAG pipelines.\n LangSmith: A platform for building production-grade LLM applications, allows you to closely monitor and evaluate your application.\n Hugging Face Evaluate: Tool for computing metrics like BLEU and ROUGE to assess text quality.\n Weights & Biases: Tracks experiments, logs metrics, and visualizes performance.\n\n## üíæ Databases\n\nThe list below features several database systems suitable for Retrieval Augmented Generation (RAG) applications. They cover a range of RAG use cases, aiding in the efficient storage and retrieval of vectors to generate responses or recommendations.\n\n Picking a vector database"
    },
    {
      "url": "https://cloud.google.com/use-cases/retrieval-augmented-generation",
      "title": "What is Retrieval-Augmented Generation (RAG)? - Google Cloud",
      "snippet": "Artifact Registry\n\n  Package manager for build artifacts and dependencies.\n\n Cloud Code\n\n  IDE support to write, run, and debug Kubernetes applications.\n\n Cloud Deploy\n\n  Fully managed continuous delivery to GKE and Cloud Run.\n\n Migrate to Containers\n\n  Components for migrating VMs into system containers on GKE.\n\n Deep Learning Containers\n\n  Containers with data science frameworks, libraries, and tools.\n\n Knative\n\n  Components to create Kubernetes-native cloud-based software.\n\n Data Analytics\n\n BigQuery\n\n  Autonomous data to AI platform for analytics and data science.\n\n Looker\n\n  Platform for BI, data applications, and embedded analytics.\n\n Dataflow\n\n  Real-time analytics for stream and batch processing.\n\n Pub/Sub\n\n  Messaging service for event ingestion and delivery.\n\n Dataproc [...] # What is Retrieval-Augmented Generation (RAG)?\n\nRAG (Retrieval-Augmented Generation) is an AI framework that combines the strengths of traditional information retrieval systems (such as search and databases) with the capabilities of generative large language models (LLMs). By combining your data and world knowledge with LLM language skills, grounded generation is more accurate, up-to-date, and relevant to your specific needs. Check out this ebook to unlock your ‚ÄúEnterprise Truth.‚Äù\n\nGet started for free\n\nGrounding for Gemini with Vertex AI Search and DIY RAG\n\n## How does Retrieval-Augmented Generation work?\n\nRAGs operate with a few main steps to help enhance generative AI outputs: [...] Software as a Service\n\n  Build better SaaS products, scale efficiently, and grow your business.\n\n Featured Products\n AI and Machine Learning\n Business Intelligence\n Compute\n Containers\n Data Analytics\n Databases\n Developer Tools\n Distributed Cloud\n Hybrid and Multicloud\n Industry Specific\n Integration Services\n Management Tools\n Maps and Geospatial\n Media Services\n Migration\n Mixed Reality\n Networking\n Operations\n Productivity and Collaboration\n Security and Identity\n Serverless\n Storage\n Web3\n\nSee all products (100+)\n\n Featured Products\n\n Compute Engine\n\n  Virtual machines running in Google‚Äôs data center.\n\n Cloud Storage\n\n  Object storage that‚Äôs secure, durable, and scalable.\n\n BigQuery\n\n  Autonomous data to AI platform for analytics and data science.\n\n Cloud Run"
    }
  ]
}