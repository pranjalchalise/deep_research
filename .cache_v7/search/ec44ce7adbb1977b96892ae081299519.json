{
  "metadata": {
    "key": "search:general:6:langchain how it works",
    "created": 1770002821.653717,
    "ttl": 86400
  },
  "data": [
    {
      "url": "https://www.ibm.com/think/topics/langchain",
      "title": "What Is LangChain? | IBM",
      "snippet": "While these integrations can generally be achieved with fully manual code, orchestration frameworks such as LangChain and the IBM watsonx portfolio of artificial intelligence products greatly simplify the process. They also make it much easier to experiment with different LLMs to compare results, as different models can be swapped in and out with minimal changes to code.\n\n## How does LangChain work?\n\nAt LangChain‚Äôs core is a development environment that streamlines the programming of LLM applications through the use of abstraction: the simplification of code by representing one or more complex processes as a named component that encapsulates all of its constituent steps. [...] LangChain serves as a generic interface for nearly any LLM, providing a centralized development environment to build LLM applications and integrate them with external data sources and software workflows. LangChain‚Äôs module-based approach allows developers and data scientists to dynamically compare different prompts and even different foundation models with minimal need to rewrite code. This modular environment also allows for programs that use multiple LLMs: for example, an application that uses one LLM to interpret user queries and another LLM to author a response. [...] LangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts necessary to work with language models. These modular components‚Äîlike functions and object classes‚Äîserve as the building blocks of generative AI programs. They can be ‚Äúchained‚Äù together to create applications, minimizing the amount of code and fine understanding required to execute complex NLP tasks. Though LangChain‚Äôs abstracted approach may limit the extent to which an expert programmer can finely customize an application, it empowers specialists and newcomers alike to quickly experiment and prototype.\n\n### Importing language models"
    },
    {
      "url": "https://www.youtube.com/watch?v=8BV9TW490nQ",
      "title": "Learn LangChain in 7 Easy Steps - Full Interactive Beginner Tutorial",
      "snippet": "notebook so what is Lang chain Lang chain is an open open source framework for developing llm applications an engine allows developers to combine llms with external sources of computation and data and the framework further simplifies the deployment of the llm applications by providing the needed tools such as tools for inspection monitoring and evaluation the deployment and monitoring tools are part of Lang Smith and Lang serf I'm not going to cover that here I'm going to cover the core Library so Lang chain combines llms with external sources of computation and data how does that work suppose that a user wants to ask a question related to some documents or some data that the user has access to now this question will be sent to the llm just like when you're interacting with chat DBT but [...] in Lang chain is a class that either passes its input through unchanged or adds additional keys to the output in the first case it acts as a placeholder and in the second case it allows us to do flexible Integrations into sequences where we need to modify the input and finally we have runnable parallel and a runnable parallel in L chain is a class that runs multiple runnables concurrently and this allows you to do branching where you have two chains run the same input but return different outputs now let's see how this works by looking at some code examples all right so I'm going to use the same symbol example throughout this section I'm going to have an llm summarize AI Concepts here I have a prompt that tells the llm to summarize an AI concept and then I'm going to inject a context into [...] as arguments we're going to pass in the list of documents with the chunks of text the embeddings the hugging phas embeddings and the reddish URL and then we're going to give it an index name let's call it YouTube and under the hood Lang chain is using the hogging face embeddings to create numeric vectors out of the text chunks and then load that to the vector database and once we have the data in the vector store we can set up the Retriever and again we use Lang chains radius object and we just call the method s Retriever with a search type and some keyword arguments and now we actually set up to do Vector similarity search over the documents in redish and just like we do with chains if we want to call the retriever we invoke it with a quiry and here we get all the chunks of data that are"
    },
    {
      "url": "https://docs.langchain.com/oss/python/langchain/overview",
      "title": "LangChain overview - Docs by LangChain",
      "snippet": "LangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.We recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.LangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and [...] ##### Agent development\n\n   LangSmith Studio\n   Test\n   Agent Chat UI\n\n##### Deploy with LangSmith\n\n   Deployment\n   Observability\n\nOn this page\n   Create an agent\n   Core benefits\n\nLangChain overview\n\nCopy page\n\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool ‚Äî so you can build agents that adapt as fast as the ecosystem evolves\n\nCopy page [...] Standard model interface ------------------------ Different providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in. Learn moreEasy to use, highly flexible agent ---------------------------------- LangChain‚Äôs agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires. Learn moreBuilt on top of LangGraph ------------------------- LangChain‚Äôs agents are built on top of LangGraph. This allows us to take advantage of LangGraph‚Äôs durable execution, human-in-the-loop support,"
    },
    {
      "url": "https://www.langchain.com/langchain",
      "title": "Build agents faster, your way - LangChain",
      "snippet": "How do I use LangChain with LangSmith?\n\nLangChain is an open source framework with pre-built agent architectures and as integrations to models, tools, and databases to start building agents quickly. The LangChain framework integrates seamlessly with LangSmith, our platform for agent observability, evaluation, and deployment ‚Äî you can set just one environment variable to get started.\n\nReady to start shipping reliable agents faster?\n\nGet started with tools from the LangChain product suite for every step of the agent development lifecycle.\n\nTalk to salesSign up for free\n\nProducts\n\nLangChainLangGraphLangSmith ObservabilityLangSmith EvaluationLangSmith Deployment\n\nResources\n\nGuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogDocsSupport\n\nCompany [...] Docs\n\nCompany\n\nAboutCareers\n\nPricing\n\nGet a demo\n\nTry LangSmith\n\nBuild agents faster, your way\n\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool ‚Äî so you can build agents that adapt as fast as the ecosystem evolves.\n\nGet started\n\nWhy use LangChain?\n\nShip fast with proven agent patterns\n\nBuild agents in minutes with templates for common use cases. create_agent provides a proven ReAct pattern on LangGraph's durable runtime.\n\nOpen and neutral by design\n\nSwap models, tools, and databases without rewriting your application. With 1000+ integrations, you can future-proof your stack as AI advances, with no vendor lock-in.\n\nCustomize without complexity [...] Image 13\n\nCustomize without complexity\n\nExtend agent behavior through middleware without rewriting core logic. Add human-in-the-loop approval, compress long conversations, or remove sensitive data‚Äî all with simple, composable hooks.\n\nImage 14\n\nDurable runtime\n\nLangChain runs on LangGraph‚Äôs durable runtime ‚Äî giving agents built-in persistence, rewind, checkpointing, and human-in-the-loop support.\n\nImage 15\n\nInstantly connect to your preferred LLM.\n\nSee all our integrations\n\nImage 16\n\nImage 17\n\nImage 18\n\nImage 19\n\nImage 20\n\nImage 21\n\nImage 22\n\nImage 23\n\nImage 24\n\nImage 25\n\nImage 26\n\nImage 27\n\nImage 28\n\nImage 29\n\nImage 30\n\nImage 31\n\nLangChain FAQs\n\nIs LangChain open source?\n\nYes - LangChain is an MIT-licensed open-source library and is free to use.\n\nHow do I use LangChain with LangSmith?"
    },
    {
      "url": "https://medium.com/around-the-prompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28",
      "title": "What is Langchain and why should I care as a developer? - Medium",
      "snippet": "You could also spin up a vector database (special database just for Embeddings which are a numerical way of representing the meaning of text) but this often takes a bit of work. Langchain has a memory module which provides plug and play access to multiple data store which allow you to save the message history of a conversation automatically further reducing the friction to create a chatbot for example. [...] Langchain makes creating agents using large language models simple through their agents API. Developers can use OpenAI functions or other means of executing tasks to enable to language model to take actions. [...] ### Why does langchain exist? ü§î\n\nSimply put, there are many rough edges to working with languages models today. The entire ecosystem is still developing so for developers, there is generally a lack of sufficient tooling to make production deployments of languages models.\n\nTasks like prompt chaining, logging, call backs, persistent memory, and efficient connections to multiple data sources come standard out of the box with langchain.\n\nLangchain also provides a model agnostic toolset that enables companies and developers to explore multiple LLM offerings and test what works best for their use cases. The best part is that you can do this in a single interface instead of having to linearly scale the size of a code base which each additional provider you try to support."
    },
    {
      "url": "https://www.youtube.com/watch?v=1bUy-1hGZpI",
      "title": "What is LangChain? - YouTube",
      "snippet": "conversations unless you happen to pass the chat history in as an input to your query but Lang chain solves this problem with simple utilities for adding in memory into your application and you have options retain for retaining like the entire High conversations through two options to just retain a summarization of the conversation that we've had so far and then finally the last one we'll look at are agents now agents can use a given language model as a reasoning engine to determine which actions to take and when building a chain for an agent you'll want to include inputs like a list of the available tools that it should use uh the user input like the prompts and the queries and then any other relevant previously executed steps so how can we put all of this to work for our applications [...] now stop me if you've heard this one before but there are a lot of large language models available today and they have their own capabilities and specialities what if I prefer to use one llm to interpret some user queries in my business application but a whole other llm to author a response to those queries well that scenario is exactly what Lang chain caters to Lang chain is an open-source orchestration framework for the development of applications that use large language models and it comes in both Python and JavaScript libraries it's it's essentially a generic interface for nearly any llm so you have a centralized development environment to build your large language model applications and then integrate them with stuff like data sources and software workflows now when it was launched [...] chains abstractions represent common steps and Concepts necessary to work with language models and they can be chained together to create applications minimizing the amount of code required to execute complex NLP tasks so let's start with the llm module now nearly any LM LM can be used in Lang chain you just need an API key the llm class is designed to provide a standard interface for all models so pick an llm of your choice be that a closed Source One like gp4 or an Open Source One like llama 2 or this being Lang chain pick both okay what else we got we have prompts now prompts are the instructions given to a large language model and the prompt template class in Lang chain formalizes the composition of prompts without the need to manually hardcode context and queries a prompt template"
    }
  ]
}