{
  "metadata": {
    "key": "search:general:6:How to use LangGraph for building AI agents",
    "created": 1769980461.371032,
    "ttl": 86400
  },
  "data": [
    {
      "url": "https://medium.com/pythoneers/building-ai-agent-systems-with-langgraph-9d85537a6326",
      "title": "Building AI agent systems with LangGraph | by Vishnu Sivan",
      "snippet": "The diagram illustrates how LangGraph facilitates a dynamic, cyclic workflow for AI agents. The process begins with an initial state, which contains input data or context (in this case, a message from the customer asking about the advantages of solar panels). This state is passed to an agent node, which interacts with the customer to gather information, such as obtaining their electricity bill. After this interaction, the state is updated with the gathered information and passed to an edge, which represents a decision point. At this point, the system evaluates the state and decides where to proceed next, depending on the updated information. This could lead to a tool interaction or move directly towards an end state. [...] ## Experimenting with LangGraph\n\nLet‚Äôs build an agent using LangGraph to gain a deeper understanding. We will start by implementing tool calls, then utilize a pre-built agent, and finally, create our own custom agent within LangGraph.\n\n### Pre-requisites\n\nThis tutorial is built using OpenAI, the Weather API, Together, and Tavily. If you have an OpenAI API key, you can use that throughout the tutorial, or you can work with other powerful proprietary models such as GPT-4 and Gemini Pro. You can also opt for open-access models such as Mixtral and Llama-3.2. For LLM inferencing, there are several platforms available, such as Abacus, Anyscale and Together. [...] ### Overview\n\n LangGraph is a library built on top of LangChain, designed to create cyclic graphs for LLM-based AI agents.\n It enables cyclic graph topologies for workflows, allowing more flexible and nuanced agent behaviors than linear models.\n Utilizes key elements:  \n   ‚Äî Nodes: Represent functions or LangChain runnable items.  \n   ‚Äî Edges: Define execution and data flow.  \n   ‚Äî Stateful graphs: Manage persistent data across execution cycles.\n Supports multi-agent coordination, allowing each agent to have its own prompt, LLM, tools and custom code within a single graph.\n Introduces a chat agent executor that represents agent state as a list of messages, ideal for chat-based models.\n\n### Key Components"
    },
    {
      "url": "https://community.intersystems.com/post/building-ai-agents-zero-hero",
      "title": "Building AI Agents: From Zero to Hero",
      "snippet": "When operating LangGraph, keep in mind the following:\n\n Design with Flexibility: Leverage the powerful graph structure to account for potential workflow branches and interactions that are not strictly linear.\n Interact with Tools Thoughtfully: Enhance but do not replace LLM capabilities with external tools. Provide each tool with comprehensive descriptions to enable precise usage.\n Employ Rich Memory Solutions: Use memory efficiently, be mindful of the LLM's context window, and consider integrating external solutions for automatic fact management.\n\nNow that we have covered the basics of LangGraph, let's dive into a practical example. To achieve this, we will develop an AI agent specifically designed for customer support. [...] Whether you are building a chatbot with real memory, an interactive story engine, or a team of agents tackling a complex problem, LangGraph turns headache-inducing plumbing into a clean, visual state machine.\n\n# Getting Started\n\nTo start with LangGraph, you will need a basic setup that typically involves installing such essential libraries as langgraph and langchain-openai. From there, you can define the nodes (tasks) and edges (connections) within the graph, effectively implementing checkpoints for short-term memory and utilizing Zep for more persistent memory needs.\n\nWhen operating LangGraph, keep in mind the following: [...] Article\n Henry Pereira ¬∑ Jun 11, 2025\n 15m read\n\nOpen Exchange\n\n# Building AI Agents: From Zero to Hero\n\n#Framework #Python #Tools #Vector Search #InterSystems IRIS\n\nLearn how to design scalable, autonomous AI agents that combine reasoning, vector search, and tool integration using LangGraph.\n\n# Too Long; Didn't Read\n\n AI Agents are proactive systems that combine memory, context, and initiative to automate tasks beyond simple chatbots.\n LangGraph is a framework that enables us to build complex AI workflows, utilizing nodes (tasks) and edges (connections) with built-in state management.\n This guide will walk you through building an AI-powered customer support agent that classifies priorities, identifies relevant topics, and determines whether to escalate or auto-reply."
    },
    {
      "url": "https://www.datacamp.com/tutorial/langgraph-agents",
      "title": "How to Build LangGraph Agents Hands-On Tutorial",
      "snippet": "# LangGraph Agents Hands-On Tutorial\n\nMaster LangGraph fundamentals ‚Äî state, nodes, edges, memory ‚Äî and build scalable AI agents with ReAct patterns, custom tools, and persistent state management.\n\nJul 15, 2025\n\nLangGraph is a graph-based framework for building AI agents that can reason, plan, and act through interconnected steps. Its distinguishing factor is that it lets us create cyclical, branching workflows with ease, where each node can run an LLM, tool, or function ‚Äî while managing the state automatically.\n\nThis makes LangGraph ideal for building complex, robust, multi-agent systems that need memory, error handling, and real-time decision-making. [...] ## Conclusion\n\nOverall, LangGraph is a powerful library that offers a structured and scalable approach to building agentic systems. Modeling logic as a graph of nodes and edges, with shared state and persistent memory, allows us to develop robust agents that can reason, interact, and adapt over time.\n\nAs systems grow in complexity, this framework provides the tools needed to manage memory, coordinate tool use, and maintain long-term context ‚Äî all while remaining modular and extensible.\n\nWith the core components now in place, you're equipped to design and deploy robust AI agents capable of handling real-world workflows. [...] ## LangGraph Agents\n\nNow we will be coding these Agents in LangGraph, focusing on understanding the different methods and steps involved when coding as well as visualizing these agents. \n\n### Single-agent workflow\n\nLet‚Äôs start by creating a single agent with no tools or memory. Let's start off with the imports:\n\n```\nfrom typing import TypedDict, List from langchain_core.messages import HumanMessage from langchain_openai import ChatOpenAI from langgraph.graph import StateGraph, START, END from dotenv import load_dotenv\n```\n\nThe first line states `TypedDict`, which is a Type-Annotation that is defined like this in Python:\n\n```\nfrom typing import TypedDict class Student(TypedDict): name: str grade: float s1: Student = {\"name\": \"Sam\", \"grade\": 92.5}\n```"
    },
    {
      "url": "https://www.youtube.com/watch?v=E0BtW2yt2pA",
      "title": "Build Reliable AI Agents with LangGraph - YouTube",
      "snippet": "node we pass our list of tools we defined up here and we can lay out the logic so basically edges set the logic of our agent so we can basically start we'll go to the assistant node we add this conditional Edge to go to the tools node or just back to the assistant and end so that's how you can lay out an agent really simply as a python script using Lang graph and all you then do is builder. compile that's how you compile your agent okay this agent graph now what do you do then so we have a very nice Library called Lang graph Studio which is part of Lang graph that's allows you to visualize these so I'll go aad and open that right now this is that agent we just built in studio so this is a nice IDE where I can actually look at the layout of my agent start I go to my assistant node that's [...] # Build Reliable AI Agents with LangGraph\n## AWS Developers\n1730000 subscribers\n337 likes\n\n### Description\n17004 views\nPosted: 15 Jan 2025\nJoin Lance from LangChain as he demonstrates how to build and test reliable AI agents using LangGraph, a powerful new library. Watch how to create agents with simple Python scripts, visualize their decision flows in LangGraph Studio, and test them in real-time. Perfect for developers who want to create dependable AI agents with clear control flows and easy debugging capabilities!\n\nüìö Learn more: \n\nFollow AWS Developers!\nüì∫ Instagram: \nüÜá X: \nüíº LinkedIn: \nüëæ Twitch: \n\nFollow Lance Martin!\nüõ†Ô∏è GitHub: \nüÜá X: \nüíº LinkedIn: \n\n00:00 Intro\n00:11 Code Overview\n00:54 LangGraph\n02:40 LangGraph Studio Demo\n03:55 Outro\n\n#LangGraph #LangChain #AIAgents [...] uh integration with anthropic and so you see this bind tools method is very conveniently available so that's how we bind our tools to our llm so now we have this model with tools I want to use this as an agent Lang graph makes that very easy to do so in Lang graph you can think about think about the steps you want your agent to take each step is basically a node and then steps can be connected with edges so basically Lang graph expresses control flows that agents can take as graphs with nodes and edges now this is a really simple one where I just have a single node that's my assistant node and it's basically going to call the model we defined up here now see something else that's pretty cool Lang graph has we call State States would allow you allows you to pass information between nodes"
    },
    {
      "url": "https://docs.langchain.com/oss/python/langgraph/agentic-rag",
      "title": "Build a custom RAG agent with LangGraph",
      "snippet": "Copy page\n\n‚Äã\n\nOverview\n\nIn this tutorial we will build a retrieval agent using LangGraph.LangChain offers built-in agent implementations, implemented using LangGraph primitives. If deeper customization is required, agents can be implemented directly in LangGraph. This guide demonstrates an example implementation of a retrieval agent. Retrieval agents are useful when you want an LLM to make a decision about whether to retrieve context from a vectorstore or respond to the user directly.By the end of the tutorial we will have done the following:\n1.   Fetch and preprocess documents that will be used for retrieval.\n2.   Index those documents for semantic search and create a retriever tool for the agent.\n3.   Build an agentic RAG system that can decide when to use the retriever tool. [...] ‚Äã\n\n1. Preprocess documents\n\n1.   Fetch documents to use in our RAG system. We will use three of the most recent pages from Lilian Weng‚Äôs excellent blog. We‚Äôll start by fetching the content of the pages using `WebBaseLoader` utility:\n\nCopy\n\n```\nfrom langchain_community.document_loaders import WebBaseLoader\n\nurls = [\n    \"\n    \"\n    \"\n]\n\ndocs = [WebBaseLoader(url).load() for url in urls]\n```\n\nCopy\n\n```\ndocs.page_content.strip()[:1000]\n```\n\n1.   Split the fetched documents into smaller chunks for indexing into our vectorstore:\n\nCopy\n\n```\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\ndocs_list = [item for sublist in docs for item in sublist] [...] ‚Äã\n\n3. Generate query\n\nNow we will start building components (nodes and edges) for our agentic RAG graph.Note that the components will operate on the `MessagesState` ‚Äî graph state that contains a `messages` key with a list of chat messages.\n1.   Build a `generate_query_or_respond` node. It will call an LLM to generate a response based on the current graph state (list of messages). Given the input messages, it will decide to retrieve using the retriever tool, or respond directly to the user. Note that we‚Äôre giving the chat model access to the `retriever_tool` we created earlier via `.bind_tools`:\n\nCopy\n\n```\nfrom langgraph.graph import MessagesState\nfrom langchain.chat_models import init_chat_model\n\nresponse_model = init_chat_model(\"gpt-4o\", temperature=0)"
    },
    {
      "url": "https://www.youtube.com/watch?v=1w5cCXlh7JQ",
      "title": "LangGraph Tutorial - How to Build Advanced AI Agent Systems",
      "snippet": "# LangGraph Tutorial - How to Build Advanced AI Agent Systems\n## Tech With Tim\n1930000 subscribers\n3683 likes\n\n### Description\n169577 views\nPosted: 5 May 2025\nDownload PyCharm and use it for free forever with one month of Pro included: \n\nIn this video, you're going to learn how to build AI agents using LangGraph. LangGraph is a much more professional and in-depth framework compared to something like LangChain or LlamaIndex, which allows you to build a really complicated and well thought out AI agents. If you're looking to push something into production, you want to have scalability features, and overall you just want more control, then LangGraph is what you should be using.\n\nüöÄ My Software Development Program: \n\nüì¨ Join my Newsletter: \n\nüéì Get private mentorship from me: [...] In this video, you're going to learn how to build AI agents using Langraphph. Langraph is a much more professional and in-depth framework compared to something like Langchain or Llama Index, which allows you to build a really complicated and wellthoughtout AI agent. If you're looking to push something into production, you want to have scalability features, and overall you just want more control, then Langraph is what you should be using. But it can be difficult to learn. So that's why I'm making this video. I'm going to break it down for you as simple as possible. And by the end of this, you'll know how to build AI agents and you'll have a more complex one that you can adapt and change to your use case. Now, what we're going to do here is just quickly discuss the key differences between [...] going to use a state graph. So we take in the state that we defined and then we have our nodes. Now in these nodes you can do anything that you want but typically what these nodes do is they modify the state or they check the state. So in this case all we're doing is we're invoking the LLM using all of the messages that are currently in our state. So that will come from here when we start with this message. Okay. Okay, we then take whatever the next message is and we add that into messages. Okay, then we construct a graph. So we say, all right, we want to have this node chatbot connected to this node, this function right here. We add our edge. So start edge and the end. And then we compile the graph and we run it. Now at this point when we run it, we start it with a single message. The"
    }
  ]
}