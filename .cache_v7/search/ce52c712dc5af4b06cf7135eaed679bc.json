{
  "metadata": {
    "key": "search:general:6:What is langchain and its new features?",
    "created": 1770002923.124017,
    "ttl": 86400
  },
  "data": [
    {
      "url": "https://www.ibm.com/think/topics/langchain",
      "title": "What Is LangChain? | IBM",
      "snippet": "LangChain serves as a generic interface for nearly any LLM, providing a centralized development environment to build LLM applications and integrate them with external data sources and software workflows. LangChain‚Äôs module-based approach allows developers and data scientists to dynamically compare different prompts and even different foundation models with minimal need to rewrite code. This modular environment also allows for programs that use multiple LLMs: for example, an application that uses one LLM to interpret user queries and another LLM to author a response. [...] LangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts necessary to work with language models. These modular components‚Äîlike functions and object classes‚Äîserve as the building blocks of generative AI programs. They can be ‚Äúchained‚Äù together to create applications, minimizing the amount of code and fine understanding required to execute complex NLP tasks. Though LangChain‚Äôs abstracted approach may limit the extent to which an expert programmer can finely customize an application, it empowers specialists and newcomers alike to quickly experiment and prototype.\n\n### Importing language models [...] LangChain provides a streamlined user experience with a ready-made, extensible framework for creating AI agents, so there‚Äôs no need to build new tool selection logic, reasoning loops (such as for ReAct agents), observation/action tracking or prompt orchestration and formatting.\n\nThe specific LangChain packages, classes and methods vary depending on the AI platform you intend to use. Some key components of the WatsonxLLM class that allow for communication with watsonx.ai models using LangChain include:"
    },
    {
      "url": "https://docs.langchain.com/oss/python/releases/langchain-v1",
      "title": "What's new in LangChain v1",
      "snippet": "create_agent ------------ The new standard for building agents in LangChain, replacing `langgraph.prebuilt.create_react_agent`.Standard content blocks ----------------------- A new `content_blocks` property that provides unified access to modern LLM features across providers.Simplified namespace -------------------- The `langchain` namespace has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to `langchain-classic`.\n\nTo upgrade,\n\npip\n\nuv\n\nCopy\n\n```\npip install -U langchain\n```\n\nFor a complete list of changes, see the migration guide.\n‚Äã\n\n`create_agent` [...] ##### Policies\n\n   Release policy\n   Security\n\nOn this page\n   create_agent\n   Middleware\n   Prebuilt middleware\n   Custom middleware\n   Built on LangGraph\n   Structured output\n   Standard content blocks\n   Benefits\n   Simplified package\n   Namespace\n   langchain-classic\n   Migration guide\n   Reporting issues\n   Additional resources\n   See also\n\nReleases\n\nReleases\n\nWhat's new in LangChain v1\n\nCopy page\n\nCopy page\n\nLangChain v1 is a focused, production-ready foundation for building agents. We‚Äôve streamlined the framework around three core improvements: [...] ‚Äã\n\nSimplified package\n\nLangChain v1 streamlines the `langchain` package namespace to focus on essential building blocks for agents. The refined namespace exposes the most useful and relevant functionality:\n### ‚Äã\n\nNamespace\n\n| Module | What‚Äôs available | Notes |\n --- \n| `langchain.agents` | `create_agent`, `AgentState` | Core agent creation functionality |\n| `langchain.messages` | Message types, content blocks, `trim_messages` | Re-exported from `langchain-core` |\n| `langchain.tools` | `@tool`, `BaseTool`, injection helpers | Re-exported from `langchain-core` |\n| `langchain.chat_models` | `init_chat_model`, `BaseChatModel` | Unified model initialization |\n| `langchain.embeddings` | `Embeddings`, `init_embeddings` | Embedding models |"
    },
    {
      "url": "https://docs.langchain.com/oss/javascript/releases/langchain-v1",
      "title": "What's new in LangChain v1",
      "snippet": "createAgent ----------- A new standard way to build agents in LangChain, replacing `createReactAgent` from LangGraph with a cleaner, more powerful API.Standard content blocks ----------------------- A new `contentBlocks` property that provides unified access to modern LLM features across all providers.Simplified package ------------------ The `langchain` package has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to `@langchain/classic`.\n\nTo upgrade,\n\nnpm\n\npnpm\n\nyarn\n\nbun\n\nCopy\n\n```\nnpm install langchain @langchain/core\n```\n\nFor a complete list of changes, see the migration guide.\n‚Äã\n\n`createAgent` [...] ### ‚Äã\n\nBenefits\n\n   Provider agnostic: Access reasoning traces, citations, built-in tools (web search, code interpreters, etc.), and other features using the same API regardless of provider\n   Type safe: Full type hints for all content block types\n   Backward compatible: Standard content can be loaded lazily, so there are no associated breaking changes\n\nFor more information, see our guide on content blocks\n\n  \n\n‚Äã\n\nSimplified package\n\nLangChain v1 streamlines the `langchain` package namespace to focus on essential building blocks for agents. The package exposes only the most useful and relevant functionality:Most of these are re-exported from `@langchain/core` for convenience, which gives you a focused API surface for building agents.\n### ‚Äã\n\n`@langchain/classic` [...] ##### Policies\n\n   Release policy\n   Security\n\nOn this page\n   createAgent\n   Middleware\n   Prebuilt middleware\n   Custom middleware\n   Built on LangGraph\n   Structured output\n   Standard content blocks\n   Benefits\n   Simplified package\n   @langchain/classic\n   What‚Äôs in @langchain/classic\n   Reporting issues\n   Additional resources\n   See also\n\nReleases\n\nReleases\n\nWhat's new in LangChain v1\n\nCopy page\n\nCopy page\n\nLangChain v1 is a focused, production-ready foundation for building agents. We‚Äôve streamlined the framework around three core improvements:"
    },
    {
      "url": "https://medium.com/mitb-for-all/langchain-a-second-look-6ed720e27fec",
      "title": "LangChain 1.0 ‚Äî A second look - Medium",
      "snippet": "LangChain 1.0 is a vast improvement over the 0.3 LangChain frameworks ‚Äî it is a comprehensive rewrite with many new, meaningful features. LangGraph 1.0 is a modest yet meaningful improvement, deliberately re-designed to fit better with LangChain 1.0.\n\nTo keep this article digestible, I‚Äôll cover only the meaningful improvements (there are many) of the LangChain 1.0 framework. I‚Äôll probably cover the LangGraph 1.0 framework in a separate article.\n\nAs always, all codes can be found in my GitHub repository.\n\n## TLDR: The core changes at a high level\n\nI‚Äôve identified two main core changes:\n\n### Context engineering [...] But credit where it‚Äôs due ‚Äî LangChain keeps evolving faster and smarter than everyone else.\n\nThey were:\n\n the first to abstract LLM operations as chains,\n the first to formalize agentic workflows through state graphs,\n the first to enable human-in-the-loop capabilities, and\n now, the first to center context engineering in its design.\n\nThis 1.0 rewrite deserves special appreciation. The learning curve that once felt like climbing Everest now feels like a well-paved trail ‚Äî and it‚Äôs backward compatible. üôå\n\n## üíª So‚Ä¶ Should You Code Everything in LangChain?\n\nHonestly? Almost everything, yes.\n\nLangChain still has the strongest developer ecosystem and the highest industry demand ‚Äî if you‚Äôre building or job-hunting in GenAI, you will encounter it. The good news: it‚Äôs fun to work with again."
    },
    {
      "url": "https://medium.com/@hitendra.patel2986/what-is-langchain-and-why-you-need-it-70c4c1054e59",
      "title": "What is LangChain and Why You Need It | by Hitendra Patel - Medium",
      "snippet": "At its core, LangChain is a framework that handles all the tedious, repetitive stuff you‚Äôd otherwise have to code yourself when working with Large Language Models (LLMs). Think of it as the difference between building a house with just a hammer versus having access to power tools, blueprints, and pre-made components.\n\n## The ‚ÄúAha!‚Äù Moment\n\nHere‚Äôs what clicked for me: remember how we had to manually structure those message objects for OpenAI in the last article? With LangChain, you can switch between OpenAI, Google‚Äôs models, local models, or any other LLM with literally one line of code change.\n\nIt‚Äôs like having a universal remote that works with every AI model ever created. Once you learn the LangChain way of doing things, you‚Äôre not locked into any single provider or approach. [...] After spending three frustrating days trying to build a simple chatbot that could remember our conversation, I stumbled across something called LangChain. Thirty minutes later, I had rebuilt everything I‚Äôd been struggling with ‚Äî and it was better than what I‚Äôd spent days trying to create.\n\nThat‚Äôs when I realized: LangChain isn‚Äôt just helpful, it‚Äôs absolutely essential for anyone serious about building AI applications.\n\n## What is LangChain, Really? (Beyond the Buzzwords)\n\nLangChain is what I like to call the ‚ÄúSwiss Army knife‚Äù for building AI applications. But unlike most developer tools that promise to make your life easier and then don‚Äôt, LangChain actually delivers. [...] That‚Äôs about 40 lines of code just for basic memory management, and we haven‚Äôt even handled errors properly or added any advanced features.\n\n## The LangChain Way:\n\n```\nfrom langchain_openai import ChatOpenAIfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.chains import ConversationChain# Setupllm = ChatOpenAI(temperature=0.7)memory = ConversationBufferWindowMemory(k=10)conversation = ConversationChain(llm=llm, memory=memory)# Usageresponse = conversation.predict(input=\"Hello, how are you?\")\n```\n\nThat‚Äôs it. Seven lines of code, and we get better memory management than my 40-line version, plus error handling, conversation tracking, and the ability to easily switch models.\n\nMind. Blown.\n\n## The LangChain Ecosystem: Your New Toolbox\n\n## Models: Work with Any AI"
    },
    {
      "url": "https://docs.langchain.com/oss/python/langchain/overview",
      "title": "LangChain overview - Docs by LangChain",
      "snippet": "LangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.We recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.LangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and [...] ##### Agent development\n\n   LangSmith Studio\n   Test\n   Agent Chat UI\n\n##### Deploy with LangSmith\n\n   Deployment\n   Observability\n\nOn this page\n   Create an agent\n   Core benefits\n\nLangChain overview\n\nCopy page\n\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool ‚Äî so you can build agents that adapt as fast as the ecosystem evolves\n\nCopy page"
    }
  ]
}