{
  "metadata": {
    "key": "search:general:6:What are the technical details of Langchain's new features?",
    "created": 1770002869.684799,
    "ttl": 86400
  },
  "data": [
    {
      "url": "https://docs.langchain.com/oss/python/releases/changelog",
      "title": "Changelog - Docs by LangChain",
      "snippet": "Model profiles: Chat models now expose supported features and capabilities through a `.profile` attribute. These data are derived from models.dev, an open source project providing model capability data.\n   Summarization middleware: Updated to support flexible trigger points using model profiles for context-aware summarization.\n   Structured output: `ProviderStrategy` support (native structured output) can now be inferred from model profiles.\n   `SystemMessage` for `create_agent`: Support for passing `SystemMessage` instances directly to `create_agent`’s `system_prompt` parameter, enabling advanced features like cache control and structured content blocks.\n   Model retry middleware: New middleware for automatically retrying failed model calls with configurable exponential backoff. [...] Copy page\n\nSubscribe: Our changelog includes an RSS feed that can integrate with Slack, email, Discord bots like Readybot or RSS Feeds to Discord Bot, and other subscription tools.\n\n​\n\nDec 15, 2025\n\nlangchain integrations\n\n​\n\n`langchain` v1.2.0\n\n   `create_agent`: Simplified support for provider-specific tool parameters and definitions via a new `extras` attribute on tools. Examples: \n       Provider-specific configuration such as Anthropic’s programmatic tool calling and tool search.\n       Built-in tools that are executed client-side, as supported by Anthropic, OpenAI, and other providers.\n\n   Support for strict schema-adherence in agent `response_format` (see `ProviderStrategy` docs).\n\n​\n\nDec 8, 2025\n\nlangchain integrations\n\n​\n\n`langchain-google-genai` v4.0.0 [...] Content moderation middleware: OpenAI content moderation middleware for detecting and handling unsafe content in agent interactions. Supports checking user input, model output, and tool results."
    },
    {
      "url": "https://docs.langchain.com/oss/javascript/releases/changelog",
      "title": "Changelog - Docs by LangChain",
      "snippet": "Model profiles: Chat models now expose supported features and capabilities through a `.profile` getter. These data are derived from models.dev, an open source project providing model capability data.\n   Model retry middleware: New middleware for automatically retrying failed model calls with configurable exponential backoff, improving agent reliability.\n   Content moderation middleware: OpenAI content moderation middleware for detecting and handling unsafe content in agent interactions. Supports checking user input, model output, and tool results.\n   Summarization middleware: Updated to support flexible trigger points using model profiles for context-aware summarization. [...] Structured output: `ProviderStrategy` support (native structured output) can now be inferred from model profiles.\n   `SystemMessage` for `createAgent`: Support for passing `SystemMessage` instances directly to `createAgent`’s `systemPrompt` parameter and a new `concat` method for extending system messages. Enables advanced features like cache control and structured content blocks.\n   Dynamic system prompt middleware: Return values from `dynamicSystemPromptMiddleware` are now purely additive. When returning a `SystemMessage` or `string`, they are merged with existing system messages rather than replacing them, making it easier to compose multiple middleware that modify the prompt. [...] ### ​\n\nNew state value primitives\n\n   ReducedValue: Define fields with custom reducers for accumulating values. Supports separate input and output schemas for type-safe reducer inputs.\n   UntrackedValue: Define transient state that exists during execution but is never checkpointed - useful for database connections, caches, or runtime-only configuration.\n   MessagesValue: A prebuilt `ReducedValue` for chat messages with the standard messages reducer.\n\n### ​\n\nType helper exports\n\nNew exported type utilities for typing functions outside the graph builder:\n   `GraphNode<Schema, Nodes?, Config?>` - Type node functions with full inference\n   `ConditionalEdgeRouter<Schema, Nodes?>` - Type conditional edge routers\n\nCopy"
    },
    {
      "url": "https://docs.langchain.com/oss/python/releases/langchain-v1",
      "title": "What's new in LangChain v1",
      "snippet": "create_agent ------------ The new standard for building agents in LangChain, replacing `langgraph.prebuilt.create_react_agent`.Standard content blocks ----------------------- A new `content_blocks` property that provides unified access to modern LLM features across providers.Simplified namespace -------------------- The `langchain` namespace has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to `langchain-classic`.\n\nTo upgrade,\n\npip\n\nuv\n\nCopy\n\n```\npip install -U langchain\n```\n\nFor a complete list of changes, see the migration guide.\n​\n\n`create_agent` [...] Structured output\n\n`create_agent` has improved structured output generation:\n   Main loop integration: Structured output is now generated in the main loop instead of requiring an additional LLM call\n   Structured output strategy: Models can choose between calling tools or using provider-side structured output generation\n   Cost reduction: Eliminates extra expense from additional LLM calls\n\nCopy\n\n```\nfrom langchain.agents import create_agent\nfrom langchain.agents.structured_output import ToolStrategy\nfrom pydantic import BaseModel\n\nclass Weather(BaseModel):\n    temperature: float\n    condition: str\n\ndef weather_tool(city: str) -> str:\n    \"\"\"Get the weather for a city.\"\"\"\n    return f\"it's sunny and 70 degrees in {city}\" [...] ​\n\nSimplified package\n\nLangChain v1 streamlines the `langchain` package namespace to focus on essential building blocks for agents. The refined namespace exposes the most useful and relevant functionality:\n### ​\n\nNamespace\n\n| Module | What’s available | Notes |\n --- \n| `langchain.agents` | `create_agent`, `AgentState` | Core agent creation functionality |\n| `langchain.messages` | Message types, content blocks, `trim_messages` | Re-exported from `langchain-core` |\n| `langchain.tools` | `@tool`, `BaseTool`, injection helpers | Re-exported from `langchain-core` |\n| `langchain.chat_models` | `init_chat_model`, `BaseChatModel` | Unified model initialization |\n| `langchain.embeddings` | `Embeddings`, `init_embeddings` | Embedding models |"
    },
    {
      "url": "https://docs.langchain.com/oss/javascript/releases/langchain-v1",
      "title": "What's new in LangChain v1",
      "snippet": "createAgent ----------- A new standard way to build agents in LangChain, replacing `createReactAgent` from LangGraph with a cleaner, more powerful API.Standard content blocks ----------------------- A new `contentBlocks` property that provides unified access to modern LLM features across all providers.Simplified package ------------------ The `langchain` package has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to `@langchain/classic`.\n\nTo upgrade,\n\nnpm\n\npnpm\n\nyarn\n\nbun\n\nCopy\n\n```\nnpm install langchain @langchain/core\n```\n\nFor a complete list of changes, see the migration guide.\n​\n\n`createAgent` [...] ### ​\n\nBenefits\n\n   Provider agnostic: Access reasoning traces, citations, built-in tools (web search, code interpreters, etc.), and other features using the same API regardless of provider\n   Type safe: Full type hints for all content block types\n   Backward compatible: Standard content can be loaded lazily, so there are no associated breaking changes\n\nFor more information, see our guide on content blocks\n\n  \n\n​\n\nSimplified package\n\nLangChain v1 streamlines the `langchain` package namespace to focus on essential building blocks for agents. The package exposes only the most useful and relevant functionality:Most of these are re-exported from `@langchain/core` for convenience, which gives you a focused API surface for building agents.\n### ​\n\n`@langchain/classic` [...] Structured output\n\n`createAgent` has improved structured output generation:\n   Main loop integration: Structured output is now generated in the main loop instead of requiring an additional LLM call\n   Structured output strategy: Models can choose between calling tools or using provider-side structured output generation\n   Cost reduction: Eliminates extra expense from additional LLM calls\n\nCopy\n\n```\nimport { createAgent } from \"langchain\";\nimport  as z from \"zod\";\n\nconst weatherSchema = z.object({\n  temperature: z.number(),\n  condition: z.string(),\n});\n\nconst agent = createAgent({\n  model: \"gpt-4o-mini\",\n  tools: [getWeather],\n  responseFormat: weatherSchema,\n});\n\nconst result = await agent.invoke({\n  messages: [\n    { role: \"user\", content: \"What is the weather in Tokyo?\" },\n  ],\n});"
    },
    {
      "url": "https://changelog.langchain.com/announcements/langchain-1-0-now-generally-available",
      "title": "LangChain 1.0 now generally available",
      "snippet": "Improved structured output generation: Integrated directly into the main agent loop, reducing both latency and cost by eliminating extra LLM calls. Fine-grained control over generation strategy via tool calling or provider-native structured output.\n\n   Standard content blocks: Provider-agnostic spec for model outputs that works consistently across OpenAI, Anthropic, and hundreds of other providers. Includes support for reasoning traces, citations, and server-side tool calls with full backward compatibility.\n\nWe also reduced the surface area of the package to focus on core abstractions. Legacy functionality has been moved to `langchain-classic` for backwards compatibility.\n\nCheck out our new documentation at docs.langchain.com or read our blog post to learn more. [...] DATE:October 22, 2025\n\nAUTHOR: The LangChain Team \n\nLangChain 1.0 is our first major stable release, marking our commitment to no breaking changes until 2.0. After three years of feedback, we've streamlined the framework to focus on what matters most: building agents quickly while having the flexibility to customize when needed.\n\nWhat we shipped:\n\n   create_agent abstraction: The fastest way to build an agent with any model provider, built on LangGraph runtime for reliability.\n\n   Middleware system: Fine-grained control at every step of the agent loop. Ships with built-in middleware for human-in-the-loop, summarization, and PII redaction. Support for custom middleware lets you hook into any point in the agent execution."
    },
    {
      "url": "https://latenode.com/blog/ai-frameworks-technical-infrastructure/langchain-setup-tools-agents-memory/langchain-framework-2025-complete-features-guide-real-world-use-cases-for-developers",
      "title": "LangChain Framework 2025: Complete Features Guide + Real ...",
      "snippet": "## LangChain Mastery in 2025 | Full 5 Hour Course [LangChain v0.3]\n\n## Core LangChain Framework Features\n\nLangChain provides a versatile set of tools for building advanced AI applications with a modular and flexible design.\n\n### Chains: Building Blocks for Workflow Design\n\nChains form the backbone of LangChain’s modular system, enabling developers to link multiple AI tasks into seamless workflows. A basic chain might combine a prompt template, an LLM call, and an output parser, while more intricate chains can coordinate dozens of interrelated steps. [...] The Sequential Chain processes tasks in a linear flow, where each step directly feeds the next. For instance, a content analysis workflow might start by summarizing a document, then extract its key themes, and finally generate actionable recommendations. This ensures a logical progression of data through the chain.\n\nRouter Chains introduce conditional logic, directing inputs to specific processing paths based on their content. For example, in a customer service scenario, technical questions could be routed to one chain, while billing inquiries are sent to another - each tailored for optimal responses. [...] ### Vector Database and Retrieval Features\n\nLangChain integrates with vector databases to enable retrieval-augmented generation (RAG), connecting LLMs to external knowledge sources. Supported vector stores include Chroma, Pinecone, and Weaviate, offering a unified interface across various backends.\n\nThe retrieval process involves embedding user queries, searching for similar document chunks, and incorporating relevant context into prompts. LangChain’s VectorStoreRetriever manages this workflow, but its performance hinges on factors like embedding quality and search parameters."
    }
  ]
}