{
  "metadata": {
    "key": "search:general:6:How do the new features of Langchain operate?",
    "created": 1770002892.041752,
    "ttl": 86400
  },
  "data": [
    {
      "url": "https://docs.langchain.com/oss/python/releases/changelog",
      "title": "Changelog - Docs by LangChain",
      "snippet": "Model profiles: Chat models now expose supported features and capabilities through a `.profile` attribute. These data are derived from models.dev, an open source project providing model capability data.\n   Summarization middleware: Updated to support flexible trigger points using model profiles for context-aware summarization.\n   Structured output: `ProviderStrategy` support (native structured output) can now be inferred from model profiles.\n   `SystemMessage` for `create_agent`: Support for passing `SystemMessage` instances directly to `create_agent`’s `system_prompt` parameter, enabling advanced features like cache control and structured content blocks.\n   Model retry middleware: New middleware for automatically retrying failed model calls with configurable exponential backoff. [...] Copy page\n\nSubscribe: Our changelog includes an RSS feed that can integrate with Slack, email, Discord bots like Readybot or RSS Feeds to Discord Bot, and other subscription tools.\n\n​\n\nDec 15, 2025\n\nlangchain integrations\n\n​\n\n`langchain` v1.2.0\n\n   `create_agent`: Simplified support for provider-specific tool parameters and definitions via a new `extras` attribute on tools. Examples: \n       Provider-specific configuration such as Anthropic’s programmatic tool calling and tool search.\n       Built-in tools that are executed client-side, as supported by Anthropic, OpenAI, and other providers.\n\n   Support for strict schema-adherence in agent `response_format` (see `ProviderStrategy` docs).\n\n​\n\nDec 8, 2025\n\nlangchain integrations\n\n​\n\n`langchain-google-genai` v4.0.0 [...] Content moderation middleware: OpenAI content moderation middleware for detecting and handling unsafe content in agent interactions. Supports checking user input, model output, and tool results."
    },
    {
      "url": "https://latenode.com/blog/ai-frameworks-technical-infrastructure/langchain-setup-tools-agents-memory/langchain-framework-2025-complete-features-guide-real-world-use-cases-for-developers",
      "title": "LangChain Framework 2025: Complete Features Guide + Real ...",
      "snippet": "For example, in content creation pipelines, one agent might gather research, another draft content, and a third review it for quality. These agents operate independently but share context through LangChain's memory systems. Similarly, in document processing workflows, one agent might extract data, another validate it, and yet another generate summaries. By chaining these steps, the entire workflow remains streamlined and coherent.\n\nHowever, debugging multi-agent systems can be tricky. When agents make independent decisions, understanding and resolving issues can become challenging due to the abstraction layers that obscure individual decision-making processes. This highlights the balance between achieving sophisticated automation and managing potential debugging complexities. [...] One practical application is automated testing systems. LangChain can analyze codebases, understand function signatures, and generate extensive test suites. Its ability to maintain context across multiple files makes it particularly effective for large-scale test generation.\n\nCode review automation is another area where LangChain shines. These tools analyze code changes, identify potential issues, suggest improvements, and ensure adherence to coding standards. For example, they can review pull requests and provide detailed feedback in natural language. [...] The Sequential Chain processes tasks in a linear flow, where each step directly feeds the next. For instance, a content analysis workflow might start by summarizing a document, then extract its key themes, and finally generate actionable recommendations. This ensures a logical progression of data through the chain.\n\nRouter Chains introduce conditional logic, directing inputs to specific processing paths based on their content. For example, in a customer service scenario, technical questions could be routed to one chain, while billing inquiries are sent to another - each tailored for optimal responses."
    },
    {
      "url": "https://docs.langchain.com/oss/javascript/releases/langchain-v1",
      "title": "What's new in LangChain v1",
      "snippet": "Built on LangGraph\n\nBecause `createAgent` is built on LangGraph, you automatically get built in support for long running and reliable agents via:\n\nPersistence\n\nConversations automatically persist across sessions with built-in checkpointing\n\nStreaming\n\nStream tokens, tool calls, and reasoning traces in real-time\n\nHuman-in-the-loop\n\nPause agent execution for human approval before sensitive actions\n\nTime travel\n\nRewind conversations to any point and explore alternate paths and prompts\n\nYou don’t need to learn LangGraph to use these features—they work out of the box.\n### ​\n\nStructured output [...] createAgent ----------- A new standard way to build agents in LangChain, replacing `createReactAgent` from LangGraph with a cleaner, more powerful API.Standard content blocks ----------------------- A new `contentBlocks` property that provides unified access to modern LLM features across all providers.Simplified package ------------------ The `langchain` package has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to `@langchain/classic`.\n\nTo upgrade,\n\nnpm\n\npnpm\n\nyarn\n\nbun\n\nCopy\n\n```\nnpm install langchain @langchain/core\n```\n\nFor a complete list of changes, see the migration guide.\n​\n\n`createAgent` [...] Prebuilt middleware\n\nLangChain provides a few prebuilt middlewares for common patterns, including:\n   `summarizationMiddleware`: Condense conversation history when it gets too long\n   `humanInTheLoopMiddleware`: Require approval for sensitive tool calls\n   `piiRedactionMiddleware`: Redact sensitive information before sending to the model\n\nCopy\n\n```\nimport {\n  createAgent,\n  summarizationMiddleware,\n  humanInTheLoopMiddleware,\n  piiRedactionMiddleware,\n} from \"langchain\";"
    },
    {
      "url": "https://focused.io/lab/langchain-under-the-hood-5-features-we-rely-on-daily",
      "title": "LangChain Under the Hood: 5 Features We Rely On Daily | Focused",
      "snippet": "## Bonus: LLMs That Take Action with Tool Calling\n\nLangChain's tool system allows LLMs to call external functions and APIs. Tools transform LLMs from text generators into action-taking agents that can interact with external systems. In LangChain, tools are declared using the @tool decorator which is used to associate a function with a schema that defines the function’s name, description and expected arguments. We can then bind the tool to an LLM so that it has the tool at its disposal. Given a request, the LLM decides whether or not it needs to call a tool it has in its toolbox to satisfy the request and how the call(s) should be structured according to the tool schema.\n\nLet’s supercharge our research assistant with the ability to search for the latest LangChain news. [...] ## Bonus: LLMs That Take Action with Tool Calling\n\nLangChain's tool system allows LLMs to call external functions and APIs. Tools transform LLMs from text generators into action-taking agents that can interact with external systems. In LangChain, tools are declared using the @tool decorator which is used to associate a function with a schema that defines the function’s name, description and expected arguments. We can then bind the tool to an LLM so that it has the tool at its disposal. Given a request, the LLM decides whether or not it needs to call a tool it has in its toolbox to satisfy the request and how the call(s) should be structured according to the tool schema.\n\nLet’s supercharge our research assistant with the ability to search for the latest LangChain news. [...] ## Bonus: LLMs That Take Action with Tool Calling\n\nLangChain's tool system allows LLMs to call external functions and APIs. Tools transform LLMs from text generators into action-taking agents that can interact with external systems. In LangChain, tools are declared using the @tool decorator which is used to associate a function with a schema that defines the function’s name, description and expected arguments. We can then bind the tool to an LLM so that it has the tool at its disposal. Given a request, the LLM decides whether or not it needs to call a tool it has in its toolbox to satisfy the request and how the call(s) should be structured according to the tool schema.\n\nLet’s supercharge our research assistant with the ability to search for the latest LangChain news."
    },
    {
      "url": "https://docs.langchain.com/oss/python/releases/langchain-v1",
      "title": "What's new in LangChain v1",
      "snippet": "Built on LangGraph\n\nBecause `create_agent` is built on LangGraph, you automatically get built in support for long running and reliable agents via:\n\nPersistence\n\nConversations automatically persist across sessions with built-in checkpointing\n\nStreaming\n\nStream tokens, tool calls, and reasoning traces in real-time\n\nHuman-in-the-loop\n\nPause agent execution for human approval before sensitive actions\n\nTime travel\n\nRewind conversations to any point and explore alternate paths and prompts\n\nYou don’t need to learn LangGraph to use these features—they work out of the box.\n### ​\n\nStructured output [...] create_agent ------------ The new standard for building agents in LangChain, replacing `langgraph.prebuilt.create_react_agent`.Standard content blocks ----------------------- A new `content_blocks` property that provides unified access to modern LLM features across providers.Simplified namespace -------------------- The `langchain` namespace has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to `langchain-classic`.\n\nTo upgrade,\n\npip\n\nuv\n\nCopy\n\n```\npip install -U langchain\n```\n\nFor a complete list of changes, see the migration guide.\n​\n\n`create_agent` [...] Prebuilt middleware\n\nLangChain provides a few prebuilt middlewares for common patterns, including:\n   `PIIMiddleware`: Redact sensitive information before sending to the model\n   `SummarizationMiddleware`: Condense conversation history when it gets too long\n   `HumanInTheLoopMiddleware`: Require approval for sensitive tool calls\n\nCopy\n\n```\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import (\n    PIIMiddleware,\n    SummarizationMiddleware,\n    HumanInTheLoopMiddleware\n)"
    },
    {
      "url": "https://medium.com/mitb-for-all/langchain-a-second-look-6ed720e27fec",
      "title": "LangChain 1.0 — A second look",
      "snippet": "LangChain now allows us to batch invoke an LLM:\n\n```\nquestions = [ \"How can quantum computing be used together with generative AI to develop new algorithms for drug discovery?\", \"How do you think we can save the world from climate change?\", \"What are the ethical implications of using AI in healthcare?\",]responses = llm.batch(questions)for response in responses: print(response)\n```\n\nThe `batch` method allows us to send multiple questions concurrently. But this method will only return the output once all the responses are collected. To receive individual outputs as it is done:\n\n```\nfor response in llm.batch_as_completed(questions): print(response)\n```\n\nThe way to stream and use an LLM to return structured outputs is unchanged.\n\n### Callbacks and Configs — extra settings [...] This is my favorite part of LangChain 1.0.\n\nThe framework now introduces middleware abstractions, which are honestly a game-changer. They let you hook directly into agent, tool, or LLM interactions — and cleanly control what happens before, during, and after each run.\n\nThink of middleware as your way to enforce context quarantine, prevent context pollution, or even add subtle debugging or instrumentation logic without cluttering your main code.\n\nLet’s say:\n\n I want to limit model calls in the agent and terminate the agent once the limit is reached,\n I want to limit tool calls in a single invocation and return an error once the number of tool calls reaches it’s limited.\n\n### LangChain’s default middleware classes [...] Before LangChain 1.0, it was common practice to create a single agent with LangGraph’s prebuilt `create_react_agent` and then orchestrate it further with LangGraph — even if you had only one agent.\n\nWhy? Because you’d often need to insert pre-processing or post-validation steps before and after the agent call.\n\nNow you can do all of that within LangChain itself — no LangGraph required. You can even inject custom logic during LLM or tool interactions, giving you fine-grained control without additional orchestration complexity.\n\nIn other words: fewer moving parts, more flexibility.\n\n## ⚙️ Middleware — the New Heart of LangChain\n\nThis is my favorite part of LangChain 1.0."
    }
  ]
}