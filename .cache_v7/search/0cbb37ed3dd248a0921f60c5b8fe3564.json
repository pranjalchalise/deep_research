{
  "metadata": {
    "key": "search:general:6:John Smith OpenAI GPT-3 project contributions",
    "created": 1769910223.454582,
    "ttl": 86400
  },
  "data": [
    {
      "url": "https://dev.to/cloudx/exploring-the-world-of-ai-with-john-smith-senior-software-engineer-at-openai-2l6d",
      "title": "Exploring the World of AI with John Smith, Senior Software Engineer ...",
      "snippet": "As a journalist, I had the opportunity to interview John Smith, a senior software engineer at OpenAI, about his work and the exciting world of artificial intelligence.\n\nJohn shared with me some insights into his daily routine as a software engineer, including his responsibilities for leading the development of complex AI projects such as chatbot GPT-3 and mentoring junior team members. He also spoke about the potential impacts of AI on language and communication, and how it could potentially make it easier for people to communicate with each other and bridge language barriers. [...] John shared with us his thoughts on the development of GPT-3 and other AI projects at OpenAI, and the ways in which AI could potentially change the way we communicate and interact with each other. He also highlighted the importance of approaching the development and use of AI with caution and consideration for its potential impacts and consequences, and ensuring that the benefits of AI are shared and distributed fairly across society.\n\nOverall, it was a thought-provoking and illuminating conversation that gave us a deeper understanding of the dynamic and rapidly-evolving field of artificial intelligence. Thank you, John, for sharing your expertise and insights with us!\n\n## The Impact\n\nJohn Smith is an avatar in a role game created with Assistant, the last version of GPT-3 from Open AI. [...] A: As a senior software engineer at OpenAI, I have a lot of responsibility and a wide range of tasks and responsibilities. Some of my key duties include leading the development of complex AI projects, mentoring and providing guidance to junior team members, and collaborating with researchers and data scientists to design and implement new AI models and algorithms. I also participate in high-level planning and strategy sessions to shape the direction of our research and development efforts, and work closely with other teams and departments within the company to ensure that our work is aligned with business goals and objectives.\n\nQ: What sets GPT-3 apart from other chatbots and language processing AI models?"
    },
    {
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10306283/",
      "title": "AI model GPT-3 (dis)informs us better than humans - PMC",
      "snippet": "### “The hard ones”\n\nWe defined tweets that were difficult to identify correctly for respondents (we called them “the hard ones”) as follows. False identified as true: false tweets with average scores >0.75; true identified as false: true tweets with scores <0.25; synthetic identified as organic: synthetic tweets with average scores >0.75; and organic identified as synthetic: organic tweets with scores <0.25.\n\n## Acknowledgments\n\nFunding: The authors acknowledge that they received no funding in support for this research.\n\nAuthor contributions: Conceptualization: G.S. and F.G. Methodology: G.S. and F.G. Investigation: G.S. and F.G. Validation: F.G. and N.B.-A. Visualization: F.G. Supervision: N.B.-A. Writing—original draft: G.S. and F.G. Writing—review and editing: G.S., F.G., and N.B.-A. [...] Our findings show that tweets produced by GPT-3 can both inform and disinform better than organic tweets. Synthetic tweets containing reliable information are recognized as true better and faster than true organic tweets, while false synthetic tweets are recognized as false worse than false organic tweets. Moreover, GPT-3 does not perform better than humans in recognizing both information and disinformation. The results suggest that GPT-3 may be more efficient at conveying information because it can generate text that is easier to read and understand compared to text written by humans. On the basis of these results, we propose a model for efficient communication and evaluation of information that challenges the current approach and consensus, according to which humans produce information [...] ## INTRODUCTION\n\nArtificial intelligence (AI) text generators caught much attention over the last years, especially after the release of GPT-3 in 2020 (1). GPT-3, the latest iteration of the generative pretrained transformers developed by OpenAI, is arguably the most advanced system of pretrained language representations (2). A generative pretrained transformer, in its essence, is a statistical representation of language; it is an AI engine that, based on users’ prompts, can produce very credible, and sometimes astonishing, texts (3). An initial test on people’s ability to tell whether a ∼500-word article was written by humans or GPT-3 showed a mean accuracy of 52%, just slightly better than random guessing (1)."
    },
    {
      "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/prompt-engineering?view=foundry-classic",
      "title": "Prompt engineering techniques - Azure OpenAI | Microsoft Learn",
      "snippet": "Expand table\n\n| System message | User | Assistant |\n --- \n| You're an AI assistant that helps people find information. | You'll read a paragraph, and then issue queries to a search engine in order to fact-check it. --- PARAGRAPH John Smith is married to Lucy Smith. They have five kids, and he works as a software engineer at Microsoft. What search queries should I do to fact-check this? --- Now you'll extract factual claims, and issue queries to fact-check them. When issuing a query, use the function SEARCH(\"query\") FACTUAL CLAIMS | 1. John Smith is married to Lucy Smith 2. They have five kids 3. He works as a software engineer at Microsoft QUERIES SEARCH(\"John Smith married Lucy Smith\") SEARCH(\"John Smith family size\") SEARCH(\"John Smith Microsoft software engineer\") | [...] Expand table\n\n| System message | User | Assistant |\n --- \n| You're an AI assistant that helps people find information. | You'll read a paragraph, and then issue queries to a search engine in order to fact-check it. Also explain the queries. --- PARAGRAPH John Smith is married to Lucy Smith. They have five kids, and he works as a software engineer at Microsoft. What search queries should I do to fact-check this? --- QUERIES | 1. \"John Smith Microsoft\" - To check if John Smith is indeed employed at Microsoft. 2. \"John Smith Lucy Smith\" - To check if John Smith is married to Lucy Smith. 3. \"John Smith children\" - To check if John Smith has five children. | [...] | You're an AI assistant that helps people find information. You'll provide answers exclusively from below text and respond in 100 words or less: \"At Microsoft, we're constantly discovering new ways to unleash creativity, unlock productivity, and up level skills so that more people can benefit from using AI. This is allowing our customers to … … thereby reducing the likelihood that the model generates a harmful response.”1 Answer in 100 words or less. Use bullet lists wherever possible. | Who are some of the early customers of the Azure OpenAI GPT-4 models? | Here are some of the early customers of the Azure OpenAI GPT-4 models: - Epic Healthcare: They plan to use GPT-4 to help physicians and nurses spend less time on data entry and investigation. - Coursera: They're using Azure OpenAI"
    },
    {
      "url": "https://jalt.journals.publicknowledgeproject.org/index.php/jalt/article/download/771/577",
      "title": "War of the chatbots",
      "snippet": "was the worst, as it hallucinated and came up with entirely fictitious references such as ‘ChatGPT and the Future of Higher Education Authors: John Smith and Jane Doe Year: 2023’. Jane Doe, really? [...] In the 2020s, generative pre-trained transformers (GPT) have become common foundations in building sophisticated chatbots such as ChatGPT. The ‘pre-training’ refers to the initial training process on a large text corpus, which provides a solid foundation for the model to perform well on downstream tasks with limited amounts of task-specific data (Brown et al., 2020). There are many GPT and ChatGPT spin-offs and applications. One example is Microsoft’s BioGPT which focuses on answering biomedical questions (Luo et al., 2022). ChatSonic, JasperAI, You.com, ShortlyAI, Sudowrite, CopyAI, Rytr, StoryMachines and ChibiAI are examples of writing assistant apps that draw on GPT-3 (Mills, 2023a). In the current AI gold rush, venture capitalists pour funds into AI startups, while established firms [...] GPT-3 had 175 billion parameters, Baidu’s Ernie 3.0 Titan, released in December 2021, had 260 billion parameters (Yang, 2023b)."
    },
    {
      "url": "https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf",
      "title": "Training language models to follow instructions with ...",
      "snippet": "20 Acknowledgements We’d first like to thank Lilian Weng, Jason Kwon, Boris Power, Che Chang, Josh Achiam, Steven Adler, Gretchen Krueger, Miles Brundage, Tyna Eloundou, Gillian Hadfield, Irene Soliaman, Christy Dennison, Daniel Ziegler, William Saunders, Beth Barnes, Cathy Yeh, Nick Cammaratta, Jonathan Ward, Brian Green, Irina Raicu, Subbu Vincent, Varoon Mathur, Kate Crawford, Su Lin Blodgett, Bertie Vidgen, Paul Röttger, Matt Knight, Pranav Shyam, Alec Radford, and others at OpenAI for discussions throughout the course of the project that helped shape our research direction. We’d also like to thank Sam Bowman, Matthew Rahtz, Ben Mann, Liam Fedus, Helen Ngo, Josh Achiam, Leo Gao, Jared Kaplan, Cathy Yeh, Miles Brundage, Gillian Hadfield, Cooper Raterink, Gretchen Krueger, Tyna [...] Thanks to those who contributed in various ways to the infrastructure used to train and deploy our models, including: Daniel Ziegler, William Saunders, Brooke Chan, Dave Cummings, Chris Hesse, Shantanu Jain, Michael Petrov, Greg Brockman, Felipe Such, Alethea Power, and the entire OpenAI supercomputing team. We’d also like to thank Suchir Balaji for help with recalibration, to Alper Ercetin and Justin Wang for designing the main diagram in this paper, and to the OpenAI Comms team for helping with the release, including: Steve Dowling, Hannah Wong, Natalie Summers, and Elie Georges. [...] 4This is an interface hosted by OpenAI to interact directly with models on our API; see \nopenai.com/playground.\n6 To train the very first InstructGPT models, we asked labelers to write prompts themselves. This is because we needed an initial source of instruction-like prompts to bootstrap the process, and these kinds of prompts weren’t often submitted to the regular GPT-3 models on the API. We asked labelers to write three kinds of prompts: • Plain: We simply ask the labelers to come up with an arbitrary task, while ensuring the tasks had sufficient diversity.\n• Few-shot: We ask the labelers to come up with an instruction, and multiple query/response pairs for that instruction."
    },
    {
      "url": "https://www.sciencedirect.com/science/article/pii/S266734522300024X",
      "title": "ChatGPT: A comprehensive review on background ...",
      "snippet": "## Keywords\n\nChatGPT\n\nLanguage model\n\nGPT-3.5\n\nGenerative AI\n\nConversational AI\n\nContext understanding\n\nNatural language processing\n\n## Cited by (0)\n\n© 2023 The Author. Published by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. [...] the importance of striking a balance between AI-assisted innovation and human expertise. The paper presents several ethical issues in existing computing domain and how ChatGPT can invoke challenges to such notion. This work also includes some biases and limitations of ChatGPT. It is worth to note that despite of several controversies and ethical concerns, ChatGPT has attracted remarkable attentions from academia, research, and industries in a very short span of time. [...] potential mitigation strategies. Finally, we envision the future of ChatGPT by exploring areas of further research and development, focusing on its integration with other technologies, improved human-AI interaction, and addressing the digital divide. This review offers valuable insights for researchers, developers, and stakeholders interested in the ever-evolving landscape of AI-driven conversational agents. This study explores the various ways ChatGPT has been revolutionizing scientific research, spanning from data processing and hypothesis generation to collaboration and public outreach. Furthermore, the paper examines the potential challenges and ethical concerns surrounding the use of ChatGPT in research, while highlighting the importance of striking a balance between AI-assisted"
    }
  ]
}